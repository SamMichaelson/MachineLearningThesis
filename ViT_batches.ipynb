{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cd161d-3924-4ccc-bd35-2fb929fdc833",
   "metadata": {},
   "source": [
    "## A comparison between Pytorch ,TVM and Auto-TVM for timing in classification of a small model like resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e92c42-8246-47a4-abbb-2108d007a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) is available.\n",
      "Input names in ONNX model: ['pixel_values']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ < 700)\n#define __shfl_sync(mask, var, lane, width) \\\n        __shfl((var), (lane), (width))\n\n#define __shfl_down_sync(mask, var, offset, width) \\\n        __shfl_down((var), (offset), (width))\n\n#define __shfl_up_sync(mask, var, offset, width) \\\n        __shfl_up((var), (offset), (width))\n#endif\n\n\n#if (((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 4)) || \\\n     (__CUDACC_VER_MAJOR__ > 11))\n#define TVM_ENABLE_L2_PREFETCH 1\n#else\n#define TVM_ENABLE_L2_PREFETCH 0\n#endif\n\n#ifdef _WIN32\n  using uint = unsigned int;\n  using uchar = unsigned char;\n  using ushort = unsigned short;\n  using int64_t = long long;\n  using uint64_t = unsigned long long;\n#else\n  #define uint unsigned int\n  #define uchar unsigned char\n  #define ushort unsigned short\n  #define int64_t long long\n  #define uint64_t unsigned long long\n#endif\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_2_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_take_kernel(float* __restrict__ T_take, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_power_red);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_kernel(float* __restrict__ T_subtract, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel(float* __restrict__ T_power_red, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_divide_erf_add_multiply_multiply_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_1_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_1_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_divide_kernel(float* __restrict__ T_divide, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_outer = 0; ax0_ax1_fused_outer < 29; ++ax0_ax1_fused_outer) {\n    if ((((ax0_ax1_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = p0[((((((((ax0_ax1_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 12) * 12608)) + ((((((ax0_ax1_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591) / 3) * 64)) + (((int)threadIdx.x) & 63))];\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_2_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 48; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 3072) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 3072) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[((((int)blockIdx.y) * 768) + ((int)blockIdx.x))] = ((volatile float*)red_result)[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_take_kernel(float* __restrict__ T_take, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 9)) < 75) {\n    T_take[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (((p1[(((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 151296) + (((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768))] * (1.000000e+00f / sqrtf((p0[((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 197)] + 1.000000e-12f)))) * p2[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p3[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_power_red) {\n  if (((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) < 4925) {\n    T_divide[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (T_power_red[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] * 1.302083e-03f);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 768) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[((((int)blockIdx.y) * 768) + ((int)blockIdx.x))] = ((volatile float*)red_result)[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_kernel(float* __restrict__ T_subtract, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_subtract[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] - p1[((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 3)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      float condval;\n      if ((3 <= ((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591))) {\n        condval = p0[((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 150528) + (((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768) * 196)) + (((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591) / 3) + 195) % 196) / 14) * 14)) + (((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591) / 3) + 13) % 14))];\n      } else {\n        condval = p1[((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 768) + ((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296))];\n      }\n      T_add[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (condval + p2[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NT_local[1];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[8];\n  float p0_shared_local[1];\n  float p1_shared_local[1];\n  T_batch_matmul_NT_local[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 8; ++k_outer) {\n    __syncthreads();\n    #pragma unroll\n    for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n      p0_shared[ax2_inner] = p0[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (k_outer * 8)) + ax2_inner)];\n    }\n    #pragma unroll\n    for (int ax2_inner_1 = 0; ax2_inner_1 < 8; ++ax2_inner_1) {\n      p1_shared[ax2_inner_1] = p1[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.x) * 64)) + (k_outer * 8)) + ax2_inner_1)];\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      p1_shared_local[0] = p1_shared[k_inner];\n      T_batch_matmul_NT_local[0] = (T_batch_matmul_NT_local[0] + (p0_shared_local[0] * p1_shared_local[0]));\n    }\n  }\n  T_batch_matmul_NT[(((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + ((int)blockIdx.x))] = T_batch_matmul_NT_local[0];\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_add[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = ((p1[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768)] + p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))]) + p2[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem) {\n  if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] + T_softmax_exp[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p1[(((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64) + (((int)threadIdx.x) & 63))] + p0[((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 197) * 768)) + ((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64)) + (((int)threadIdx.x) & 63))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float conv2d_nchw[56];\n  __shared__ float pad_temp_shared[43681];\n  __shared__ float p1_shared[48];\n  #pragma unroll\n  for (int ff_init = 0; ff_init < 2; ++ff_init) {\n    #pragma unroll\n    for (int yy_init = 0; yy_init < 2; ++yy_init) {\n      conv2d_nchw[((ff_init * 2) + yy_init)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 28)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 4)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 32)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 8)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 36)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 12)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 40)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 16)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 44)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 20)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 48)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 24)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 52)] = 0.000000e+00f;\n    }\n  }\n  for (int rc_outer = 0; rc_outer < 3; ++rc_outer) {\n    for (int ry_outer = 0; ry_outer < 16; ++ry_outer) {\n      for (int rx_outer = 0; rx_outer < 16; ++rx_outer) {\n        __syncthreads();\n        #pragma unroll\n        for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 261; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n          if (((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) < 3971) {\n            if (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 3641) {\n              pad_temp_shared[(((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)] = p0[(((((((((int)blockIdx.z) >> 4) * 150528) + (rc_outer * 50176)) + ((((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) / 19) * 224)) + (ry_outer * 224)) + rx_outer) + ((((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) % 209))];\n            }\n          }\n        }\n        if (((((int)threadIdx.x) >> 2) + ((int)threadIdx.z)) < 12) {\n          if (((int)threadIdx.x) < 4) {\n            p1_shared[((((int)threadIdx.z) * 4) + ((int)threadIdx.x))] = p1[(((((((((int)blockIdx.z) & 15) * 36864) + (((int)threadIdx.z) * 3072)) + (((int)threadIdx.x) * 768)) + (rc_outer * 256)) + (ry_outer * 16)) + rx_outer)];\n          }\n        }\n        __syncthreads();\n        #pragma unroll\n        for (int ff = 0; ff < 2; ++ff) {\n          #pragma unroll\n          for (int yy = 0; yy < 2; ++yy) {\n            conv2d_nchw[((ff * 2) + yy)] = (conv2d_nchw[((ff * 2) + yy)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 28)] = (conv2d_nchw[(((ff * 2) + yy) + 28)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 4)] = (conv2d_nchw[(((ff * 2) + yy) + 4)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 32)] = (conv2d_nchw[(((ff * 2) + yy) + 32)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 8)] = (conv2d_nchw[(((ff * 2) + yy) + 8)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 36)] = (conv2d_nchw[(((ff * 2) + yy) + 36)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 12)] = (conv2d_nchw[(((ff * 2) + yy) + 12)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 40)] = (conv2d_nchw[(((ff * 2) + yy) + 40)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 16)] = (conv2d_nchw[(((ff * 2) + yy) + 16)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 44)] = (conv2d_nchw[(((ff * 2) + yy) + 44)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 20)] = (conv2d_nchw[(((ff * 2) + yy) + 20)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 48)] = (conv2d_nchw[(((ff * 2) + yy) + 48)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 24)] = (conv2d_nchw[(((ff * 2) + yy) + 24)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 52)] = (conv2d_nchw[(((ff * 2) + yy) + 52)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n          }\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int ax1_inner_inner_inner = 0; ax1_inner_inner_inner < 2; ++ax1_inner_inner_inner) {\n    #pragma unroll\n    for (int ax2_inner_inner_inner = 0; ax2_inner_inner_inner < 2; ++ax2_inner_inner_inner) {\n      T_add[(((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x))] = (conv2d_nchw[((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4704)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 28)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 28)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 4)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4732)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 32)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 56)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 8)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4760)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 36)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 84)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 12)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4788)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 40)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 112)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 16)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4816)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 44)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 140)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 20)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4844)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 48)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 168)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 24)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4872)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 52)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  __shared__ float T_matmul_NT[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 768) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[0] = ((volatile float*)red_result)[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_add[((((int)blockIdx.y) * 1000) + ((int)blockIdx.x))] = (T_matmul_NT[0] + p2[((int)blockIdx.x)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel(float* __restrict__ T_power_red, float* __restrict__ p0) {\n  float T_power_red_rf[1];\n  float red_buf0[1];\n  T_power_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925) {\n      T_power_red_rf[0] = (T_power_red_rf[0] + powf(p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))], 2.000000e+00f));\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = T_power_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925)) {\n    T_power_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NT_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NT_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 25; ++k_outer) {\n    __syncthreads();\n    if (((k_outer * 8) + ((int)threadIdx.x)) < 197) {\n      p0_shared[((int)threadIdx.x)] = p0[((((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + (k_outer * 8)) + ((int)threadIdx.x))];\n    }\n    for (int ax1_inner = 0; ax1_inner < 64; ++ax1_inner) {\n      if (((k_outer * 8) + ((int)threadIdx.x)) < 197) {\n        p1_shared[((ax1_inner * 8) + ((int)threadIdx.x))] = p1[((((((int)blockIdx.z) * 12608) + (ax1_inner * 197)) + (k_outer * 8)) + ((int)threadIdx.x))];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      if (((k_outer * 8) + k_inner) < 197) {\n        p0_shared_local[0] = p0_shared[k_inner];\n      }\n      #pragma unroll\n      for (int ax1 = 0; ax1 < 8; ++ax1) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          p1_shared_local[ax1] = p1_shared[(((((int)threadIdx.x) * 64) + (ax1 * 8)) + k_inner)];\n        }\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          T_batch_matmul_NT_local[j_c] = (T_batch_matmul_NT_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NT[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NT_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_divide_erf_add_multiply_multiply_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_outer = 0; ax0_ax1_fused_outer < 116; ++ax0_ax1_fused_outer) {\n    if (((ax0_ax1_fused_outer * 128) + (((int)blockIdx.x) >> 1)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (((p1[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)] + p0[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 30259200)]) * (erff(((p1[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)] + p0[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 30259200)]) * 7.071068e-01f)) + 1.000000e+00f)) * 5.000000e-01f);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 89; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_softmax_norm[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] / T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_transpose[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p1[(((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64) + (((int)threadIdx.x) & 63))] + p0[((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 197) * 768)) + ((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64)) + (((int)threadIdx.x) & 63))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 89; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))];\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_1_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 768) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[((((int)blockIdx.y) * 3072) + ((int)blockIdx.x))] = ((volatile float*)red_result)[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_1_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_transpose[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p1[(((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296) / 197)] + p0[(((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 197) * 768)) + (((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296) / 197))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red) {\n  float p0_red_rf[1];\n  float red_buf0[1];\n  p0_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925) {\n      p0_red_rf[0] = (p0_red_rf[0] + p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = p0_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925)) {\n    p0_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red) {\n  if (((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) < 4925) {\n    T_divide[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (p0_red[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] * 1.302083e-03f);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_divide_kernel(float* __restrict__ T_divide, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_ax2_fused_ax3_fused_outer = 0; ax0_ax1_fused_ax2_fused_ax3_fused_outer < 89; ++ax0_ax1_fused_ax2_fused_ax3_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_divide[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p0[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] * 1.250000e-01f);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3) {\n  for (int ax0_ax1_fused_outer = 0; ax0_ax1_fused_outer < 29; ++ax0_ax1_fused_outer) {\n    if ((((ax0_ax1_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (((p1[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] * (1.000000e+00f / sqrtf((p0[((((ax0_ax1_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 3)] + 1.000000e-12f)))) * p2[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768)]) + p3[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))], p0[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 89; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = __expf((p0[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] - T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]));\n    }\n  }\n}\n\n\nCompilation error:\nptxas error   : Entry function 'tvmgen_default_fused_nn_conv2d_add_kernel' uses too much shared data (0x2ab44 bytes, 0xc000 max)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 370\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 370\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 66\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([            \n\u001b[1;32m     58\u001b[0m  transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m256\u001b[39m),                    \n\u001b[1;32m     59\u001b[0m  transforms\u001b[38;5;241m.\u001b[39mCenterCrop(\u001b[38;5;241m224\u001b[39m),                \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m  std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]                  \n\u001b[1;32m     64\u001b[0m )])\n\u001b[1;32m     65\u001b[0m load_random_images(batch_size)\n\u001b[0;32m---> 66\u001b[0m imgs,classes, module\u001b[38;5;241m=\u001b[39mrun_tvm(model,get_images(),batch_size)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# lib =tune(tuning_option, batch_size, model, target_device, db_path, target)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ( lib ):\n",
      "Cell \u001b[0;32mIn[1], line 103\u001b[0m, in \u001b[0;36mrun_tvm\u001b[0;34m(model, imgs, batchsize)\u001b[0m\n\u001b[1;32m    101\u001b[0m device \u001b[38;5;241m=\u001b[39m check_device()\n\u001b[1;32m    102\u001b[0m imgs\u001b[38;5;241m=\u001b[39mimgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 103\u001b[0m lib, inp_name \u001b[38;5;241m=\u001b[39m tvm_relay(model,batchsize)\n\u001b[1;32m    104\u001b[0m classes ,module \u001b[38;5;241m=\u001b[39m create_module(tvm_lib, imgs, tvm_inp_name,batchsize) \n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m imgs, classes, module\n",
      "Cell \u001b[0;32mIn[1], line 75\u001b[0m, in \u001b[0;36mtvm_relay\u001b[0;34m(model, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m mod, params, input_shape, output_shape \u001b[38;5;241m=\u001b[39m get_network(model, batch_size)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tvm\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mPassContext(opt_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 75\u001b[0m     lib \u001b[38;5;241m=\u001b[39m relay\u001b[38;5;241m.\u001b[39mbuild(mod[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m], target\u001b[38;5;241m=\u001b[39mtarget, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ( lib ):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(lib)\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/relay/build_module.py:364\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tophub_context:\n\u001b[1;32m    363\u001b[0m     bld_mod \u001b[38;5;241m=\u001b[39m BuildModule()\n\u001b[0;32m--> 364\u001b[0m     graph_json, runtime_mod, params \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mbuild(\n\u001b[1;32m    365\u001b[0m         mod\u001b[38;5;241m=\u001b[39mir_mod,\n\u001b[1;32m    366\u001b[0m         target\u001b[38;5;241m=\u001b[39mraw_targets,\n\u001b[1;32m    367\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    368\u001b[0m         executor\u001b[38;5;241m=\u001b[39mexecutor,\n\u001b[1;32m    369\u001b[0m         runtime\u001b[38;5;241m=\u001b[39mruntime,\n\u001b[1;32m    370\u001b[0m         workspace_memory_pools\u001b[38;5;241m=\u001b[39mworkspace_memory_pools,\n\u001b[1;32m    371\u001b[0m         constant_memory_pools\u001b[38;5;241m=\u001b[39mconstant_memory_pools,\n\u001b[1;32m    372\u001b[0m         mod_name\u001b[38;5;241m=\u001b[39mmod_name,\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m     func_metadata \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mget_function_metadata()\n\u001b[1;32m    375\u001b[0m     devices \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mget_devices()\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/relay/build_module.py:161\u001b[0m, in \u001b[0;36mBuildModule.build\u001b[0;34m(self, mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m autotvm\u001b[38;5;241m.\u001b[39mGLOBAL_SCOPE\u001b[38;5;241m.\u001b[39msilent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     is_auto_scheduler_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_meta_schedule_enabled() \u001b[38;5;129;01mor\u001b[39;00m old_autotvm_silent\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m mangle_module_name(mod_name)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build(\n\u001b[1;32m    162\u001b[0m     mod,\n\u001b[1;32m    163\u001b[0m     target,\n\u001b[1;32m    164\u001b[0m     target_host,\n\u001b[1;32m    165\u001b[0m     executor,\n\u001b[1;32m    166\u001b[0m     runtime,\n\u001b[1;32m    167\u001b[0m     workspace_memory_pools,\n\u001b[1;32m    168\u001b[0m     constant_memory_pools,\n\u001b[1;32m    169\u001b[0m     mod_name,\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m autotvm\u001b[38;5;241m.\u001b[39mGLOBAL_SCOPE\u001b[38;5;241m.\u001b[39msilent \u001b[38;5;241m=\u001b[39m old_autotvm_silent\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Get artifacts\u001b[39;00m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:332\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.PackedFuncBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:277\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./base.pxi:182\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.CHECK_CALL\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/_ffi/base.py:481\u001b[0m, in \u001b[0;36mraise_last_ffi_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m _LIB\u001b[38;5;241m.\u001b[39mTVMDropLastPythonError()\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:56\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.tvm_callback\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/contrib/nvcc.py:204\u001b[0m, in \u001b[0;36mtvm_callback_cuda_compile\u001b[0;34m(code, target)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;129m@tvm\u001b[39m\u001b[38;5;241m.\u001b[39m_ffi\u001b[38;5;241m.\u001b[39mregister_func\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtvm_callback_cuda_compile\u001b[39m(code, target):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"use nvcc to generate fatbin code for better optimization\"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     ptx \u001b[38;5;241m=\u001b[39m compile_cuda(code, target_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfatbin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ptx\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/contrib/nvcc.py:128\u001b[0m, in \u001b[0;36mcompile_cuda\u001b[0;34m(code, target_format, arch, options, path_target)\u001b[0m\n\u001b[1;32m    126\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCompilation error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m py_str(out)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    131\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(f\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ < 700)\n#define __shfl_sync(mask, var, lane, width) \\\n        __shfl((var), (lane), (width))\n\n#define __shfl_down_sync(mask, var, offset, width) \\\n        __shfl_down((var), (offset), (width))\n\n#define __shfl_up_sync(mask, var, offset, width) \\\n        __shfl_up((var), (offset), (width))\n#endif\n\n\n#if (((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 4)) || \\\n     (__CUDACC_VER_MAJOR__ > 11))\n#define TVM_ENABLE_L2_PREFETCH 1\n#else\n#define TVM_ENABLE_L2_PREFETCH 0\n#endif\n\n#ifdef _WIN32\n  using uint = unsigned int;\n  using uchar = unsigned char;\n  using ushort = unsigned short;\n  using int64_t = long long;\n  using uint64_t = unsigned long long;\n#else\n  #define uint unsigned int\n  #define uchar unsigned char\n  #define ushort unsigned short\n  #define int64_t long long\n  #define uint64_t unsigned long long\n#endif\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_2_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_take_kernel(float* __restrict__ T_take, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_power_red);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_kernel(float* __restrict__ T_subtract, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel(float* __restrict__ T_power_red, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_divide_erf_add_multiply_multiply_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_1_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_1_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_divide_kernel(float* __restrict__ T_divide, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_outer = 0; ax0_ax1_fused_outer < 29; ++ax0_ax1_fused_outer) {\n    if ((((ax0_ax1_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = p0[((((((((ax0_ax1_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 12) * 12608)) + ((((((ax0_ax1_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591) / 3) * 64)) + (((int)threadIdx.x) & 63))];\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_2_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 48; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 3072) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 3072) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[((((int)blockIdx.y) * 768) + ((int)blockIdx.x))] = ((volatile float*)red_result)[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_take_kernel(float* __restrict__ T_take, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3) {\n  if (((((int)blockIdx.x) * 2) + (((int)threadIdx.x) >> 9)) < 75) {\n    T_take[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (((p1[(((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 151296) + (((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768))] * (1.000000e+00f / sqrtf((p0[((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 197)] + 1.000000e-12f)))) * p2[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p3[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_power_red) {\n  if (((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) < 4925) {\n    T_divide[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (T_power_red[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] * 1.302083e-03f);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 768) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[((((int)blockIdx.y) * 768) + ((int)blockIdx.x))] = ((volatile float*)red_result)[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_kernel(float* __restrict__ T_subtract, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_subtract[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] - p1[((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 3)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      float condval;\n      if ((3 <= ((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591))) {\n        condval = p0[((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 150528) + (((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768) * 196)) + (((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591) / 3) + 195) % 196) / 14) * 14)) + (((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) % 591) / 3) + 13) % 14))];\n      } else {\n        condval = p1[((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 768) + ((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296))];\n      }\n      T_add[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (condval + p2[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NT_local[1];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[8];\n  float p0_shared_local[1];\n  float p1_shared_local[1];\n  T_batch_matmul_NT_local[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 8; ++k_outer) {\n    __syncthreads();\n    #pragma unroll\n    for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n      p0_shared[ax2_inner] = p0[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (k_outer * 8)) + ax2_inner)];\n    }\n    #pragma unroll\n    for (int ax2_inner_1 = 0; ax2_inner_1 < 8; ++ax2_inner_1) {\n      p1_shared[ax2_inner_1] = p1[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.x) * 64)) + (k_outer * 8)) + ax2_inner_1)];\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      p1_shared_local[0] = p1_shared[k_inner];\n      T_batch_matmul_NT_local[0] = (T_batch_matmul_NT_local[0] + (p0_shared_local[0] * p1_shared_local[0]));\n    }\n  }\n  T_batch_matmul_NT[(((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + ((int)blockIdx.x))] = T_batch_matmul_NT_local[0];\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_add[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = ((p1[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768)] + p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))]) + p2[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem) {\n  if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] + T_softmax_exp[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p1[(((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64) + (((int)threadIdx.x) & 63))] + p0[((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 197) * 768)) + ((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64)) + (((int)threadIdx.x) & 63))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float conv2d_nchw[56];\n  __shared__ float pad_temp_shared[43681];\n  __shared__ float p1_shared[48];\n  #pragma unroll\n  for (int ff_init = 0; ff_init < 2; ++ff_init) {\n    #pragma unroll\n    for (int yy_init = 0; yy_init < 2; ++yy_init) {\n      conv2d_nchw[((ff_init * 2) + yy_init)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 28)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 4)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 32)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 8)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 36)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 12)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 40)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 16)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 44)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 20)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 48)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 24)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 52)] = 0.000000e+00f;\n    }\n  }\n  for (int rc_outer = 0; rc_outer < 3; ++rc_outer) {\n    for (int ry_outer = 0; ry_outer < 16; ++ry_outer) {\n      for (int rx_outer = 0; rx_outer < 16; ++rx_outer) {\n        __syncthreads();\n        #pragma unroll\n        for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 261; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n          if (((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) < 3971) {\n            if (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 3641) {\n              pad_temp_shared[(((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)] = p0[(((((((((int)blockIdx.z) >> 4) * 150528) + (rc_outer * 50176)) + ((((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) / 19) * 224)) + (ry_outer * 224)) + rx_outer) + ((((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) % 209))];\n            }\n          }\n        }\n        if (((((int)threadIdx.x) >> 2) + ((int)threadIdx.z)) < 12) {\n          if (((int)threadIdx.x) < 4) {\n            p1_shared[((((int)threadIdx.z) * 4) + ((int)threadIdx.x))] = p1[(((((((((int)blockIdx.z) & 15) * 36864) + (((int)threadIdx.z) * 3072)) + (((int)threadIdx.x) * 768)) + (rc_outer * 256)) + (ry_outer * 16)) + rx_outer)];\n          }\n        }\n        __syncthreads();\n        #pragma unroll\n        for (int ff = 0; ff < 2; ++ff) {\n          #pragma unroll\n          for (int yy = 0; yy < 2; ++yy) {\n            conv2d_nchw[((ff * 2) + yy)] = (conv2d_nchw[((ff * 2) + yy)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 28)] = (conv2d_nchw[(((ff * 2) + yy) + 28)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 4)] = (conv2d_nchw[(((ff * 2) + yy) + 4)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 32)] = (conv2d_nchw[(((ff * 2) + yy) + 32)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 8)] = (conv2d_nchw[(((ff * 2) + yy) + 8)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 36)] = (conv2d_nchw[(((ff * 2) + yy) + 36)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 12)] = (conv2d_nchw[(((ff * 2) + yy) + 12)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 40)] = (conv2d_nchw[(((ff * 2) + yy) + 40)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 16)] = (conv2d_nchw[(((ff * 2) + yy) + 16)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 44)] = (conv2d_nchw[(((ff * 2) + yy) + 44)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 20)] = (conv2d_nchw[(((ff * 2) + yy) + 20)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 48)] = (conv2d_nchw[(((ff * 2) + yy) + 48)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 24)] = (conv2d_nchw[(((ff * 2) + yy) + 24)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 52)] = (conv2d_nchw[(((ff * 2) + yy) + 52)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n          }\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int ax1_inner_inner_inner = 0; ax1_inner_inner_inner < 2; ++ax1_inner_inner_inner) {\n    #pragma unroll\n    for (int ax2_inner_inner_inner = 0; ax2_inner_inner_inner < 2; ++ax2_inner_inner_inner) {\n      T_add[(((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x))] = (conv2d_nchw[((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4704)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 28)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 28)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 4)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4732)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 32)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 56)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 8)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4760)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 36)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 84)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 12)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4788)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 40)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 112)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 16)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4816)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 44)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 140)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 20)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4844)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 48)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 168)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 24)] + p2[((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4872)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 52)] + p2[(((((((int)blockIdx.z) & 15) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  __shared__ float T_matmul_NT[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 768) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[0] = ((volatile float*)red_result)[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_add[((((int)blockIdx.y) * 1000) + ((int)blockIdx.x))] = (T_matmul_NT[0] + p2[((int)blockIdx.x)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_power_mean_kernel(float* __restrict__ T_power_red, float* __restrict__ p0) {\n  float T_power_red_rf[1];\n  float red_buf0[1];\n  T_power_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925) {\n      T_power_red_rf[0] = (T_power_red_rf[0] + powf(p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))], 2.000000e+00f));\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = T_power_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925)) {\n    T_power_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NT_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NT_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 25; ++k_outer) {\n    __syncthreads();\n    if (((k_outer * 8) + ((int)threadIdx.x)) < 197) {\n      p0_shared[((int)threadIdx.x)] = p0[((((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + (k_outer * 8)) + ((int)threadIdx.x))];\n    }\n    for (int ax1_inner = 0; ax1_inner < 64; ++ax1_inner) {\n      if (((k_outer * 8) + ((int)threadIdx.x)) < 197) {\n        p1_shared[((ax1_inner * 8) + ((int)threadIdx.x))] = p1[((((((int)blockIdx.z) * 12608) + (ax1_inner * 197)) + (k_outer * 8)) + ((int)threadIdx.x))];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      if (((k_outer * 8) + k_inner) < 197) {\n        p0_shared_local[0] = p0_shared[k_inner];\n      }\n      #pragma unroll\n      for (int ax1 = 0; ax1 < 8; ++ax1) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          p1_shared_local[ax1] = p1_shared[(((((int)threadIdx.x) * 64) + (ax1 * 8)) + k_inner)];\n        }\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          T_batch_matmul_NT_local[j_c] = (T_batch_matmul_NT_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NT[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NT_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_divide_erf_add_multiply_multiply_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_outer = 0; ax0_ax1_fused_outer < 116; ++ax0_ax1_fused_outer) {\n    if (((ax0_ax1_fused_outer * 128) + (((int)blockIdx.x) >> 1)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (((p1[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)] + p0[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 30259200)]) * (erff(((p1[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)] + p0[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 30259200)]) * 7.071068e-01f)) + 1.000000e+00f)) * 5.000000e-01f);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 89; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_softmax_norm[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] / T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_transpose[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p1[(((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64) + (((int)threadIdx.x) & 63))] + p0[((((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 197) * 768)) + ((((((ax0_ax1_fused_ax2_fused_outer * 4096) + (((int)blockIdx.x) * 16)) + (((int)threadIdx.x) >> 6)) % 2364) / 197) * 64)) + (((int)threadIdx.x) & 63))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 89; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))];\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_1_kernel(float* __restrict__ T_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[(((((int)blockIdx.y) * 768) + (k_outer * 64)) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[((((int)blockIdx.y) * 3072) + ((int)blockIdx.x))] = ((volatile float*)red_result)[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_add_reshape_transpose_reshape_transpose_1_kernel(float* __restrict__ T_transpose, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 29; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_transpose[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p1[(((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296) / 197)] + p0[(((((((ax0_ax1_fused_ax2_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 591) * 151296) + (((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 197) * 768)) + (((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 151296) / 197))]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red) {\n  float p0_red_rf[1];\n  float red_buf0[1];\n  p0_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925) {\n      p0_red_rf[0] = (p0_red_rf[0] + p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = p0_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 16) + (((int)threadIdx.y) >> 1)) < 4925)) {\n    p0_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red) {\n  if (((((int)blockIdx.x) * 512) + (((int)threadIdx.x) >> 1)) < 4925) {\n    T_divide[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (p0_red[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] * 1.302083e-03f);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_divide_kernel(float* __restrict__ T_divide, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_ax2_fused_ax3_fused_outer = 0; ax0_ax1_fused_ax2_fused_ax3_fused_outer < 89; ++ax0_ax1_fused_ax2_fused_ax3_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_divide[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (p0[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] * 1.250000e-01f);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_add_rsqrt_multiply_multiply_add_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3) {\n  for (int ax0_ax1_fused_outer = 0; ax0_ax1_fused_outer < 29; ++ax0_ax1_fused_outer) {\n    if ((((ax0_ax1_fused_outer * 512) + (((int)blockIdx.x) * 2)) + (((int)threadIdx.x) >> 9)) < 14775) {\n      T_reshape[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (((p1[(((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] * (1.000000e+00f / sqrtf((p0[((((ax0_ax1_fused_outer * 1024) + (((int)blockIdx.x) * 4)) + (((int)threadIdx.x) >> 8)) / 3)] + 1.000000e-12f)))) * p2[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768)]) + p3[((((ax0_ax1_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 768)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 128) + (((int)threadIdx.x) >> 3)) < 14775) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))], p0[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 89; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 32768) + (((int)blockIdx.x) * 128)) + (((int)threadIdx.x) >> 3)) < 2910675) {\n      T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = __expf((p0[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] - T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]));\n    }\n  }\n}\n\n\nCompilation error:\nptxas error   : Entry function 'tvmgen_default_fused_nn_conv2d_add_kernel' uses too much shared data (0x2ab44 bytes, 0xc000 max)\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay, autotvm\n",
    "import tvm.relay.testing\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "import tvm.auto_scheduler as auto_scheduler\n",
    "import sqlite3\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import requests\n",
    "import ml_dtypes\n",
    "\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = \"vit\"\n",
    "    target = tvm.target.Target(\"cuda\")\n",
    "    if str(target).split()[0] == \"cuda\":\n",
    "        target_device = \"cuda\"\n",
    "    else:\n",
    "        target_device = \"llvm\"\n",
    "\n",
    "    batch_size = 50\n",
    "    dtype = \"float32\"\n",
    "    db_path = '/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tvm_report/automate_tvm.db'\n",
    "\n",
    "    tuning_option = {\n",
    "        \"log_filename\": f\"{model}.log\",\n",
    "        \"tuner\": \"xgb_rank_itervar\",\n",
    "        \"n_trial\": 2000,\n",
    "        \"early_stopping\": 400,\n",
    "        \"measure_option\": autotvm.measure_option(\n",
    "            builder=autotvm.LocalBuilder(timeout=10),\n",
    "            runner=autotvm.LocalRunner(number=5, repeat=1, timeout=4, min_repeat_ms=150),\n",
    "        ),\n",
    "    }\n",
    "    transform = transforms.Compose([            \n",
    "     transforms.Resize(256),                    \n",
    "     transforms.CenterCrop(224),                \n",
    "     transforms.ToTensor(),                     \n",
    "     transforms.Normalize(                      \n",
    "     mean=[0.485, 0.456, 0.406],                \n",
    "     std=[0.229, 0.224, 0.225]                  \n",
    "    )])\n",
    "    load_random_images(batch_size)\n",
    "    imgs,classes, module=run_tvm(model,get_images(),batch_size)\n",
    "    # lib =tune(tuning_option, batch_size, model, target_device, db_path, target)\n",
    "    if ( lib ):\n",
    "        print(lib)\n",
    "\n",
    "def tvm_relay(model,batch_size):\n",
    "    target = tvm.target.Target(\"cuda\")\n",
    "    mod, params, input_shape, output_shape = get_network(model, batch_size)\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build(mod[\"main\"], target=target, params=params)\n",
    "    if ( lib ):\n",
    "        print(lib)\n",
    "    return lib\n",
    "    \n",
    "def run_module(mod):\n",
    "    mod.run()\n",
    "    return mod\n",
    "\n",
    "def create_module(lib, imgs, input_name, batchsize):\n",
    "    dtype = \"float32\"\n",
    "    module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "    images_cpu = imgs.cpu()\n",
    "    images_np = np.array(images_cpu).reshape((batchsize, 3, 224, 224))\n",
    "    \n",
    "    # Convert NumPy array to TVM tensor\n",
    "    images_tvm = tvm.nd.array(images_np.astype(dtype))\n",
    "    \n",
    "    module.set_input(input_name, images_tvm)\n",
    "    mod = run_module(module)\n",
    "    output = mod.get_output(0).asnumpy()\n",
    "    prediction = np.argmax(output, axis=1)\n",
    "    classes = prediction_to_class(prediction)\n",
    "    return classes, module\n",
    "    \n",
    "def run_tvm(model,imgs,batchsize):\n",
    "    device = check_device()\n",
    "    imgs=imgs.to(device)\n",
    "    lib, inp_name = tvm_relay(model,batchsize)\n",
    "    classes ,module = create_module(tvm_lib, imgs, tvm_inp_name,batchsize) \n",
    "    return imgs, classes, module\n",
    "\n",
    "def check_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA (GPU) is available.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) is not available. Using CPU instead.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "    \n",
    "def load_random_images(batch_size):\n",
    "    transform = transforms.Compose([            \n",
    "     transforms.Resize(256),                    \n",
    "     transforms.CenterCrop(224),                \n",
    "     transforms.ToTensor(),                     \n",
    "     transforms.Normalize(                      \n",
    "     mean=[0.485, 0.456, 0.406],                \n",
    "     std=[0.229, 0.224, 0.225]                  \n",
    "    )])\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    files = os.listdir(directory)\n",
    "    image_files = [f for f in files if f.endswith('.JPEG')]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory.\")\n",
    "        return None\n",
    "    \n",
    "    imgs = []\n",
    "    chosen_image_files = []\n",
    "    for _ in range(batch_size):\n",
    "        random_image = random.choice(image_files)\n",
    "        img_path = os.path.join(directory, random_image)\n",
    "        chosen_image_files.append(img_path)  # Append the chosen image file path\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    \n",
    "    with open(\"image_files.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(chosen_image_files))\n",
    "    \n",
    "    return imgs\n",
    "\n",
    "def get_images():\n",
    "    transform = transforms.Compose([            \n",
    "     transforms.Resize(256),                    \n",
    "     transforms.CenterCrop(224),                \n",
    "     transforms.ToTensor(),                     \n",
    "     transforms.Normalize(                      \n",
    "     mean=[0.485, 0.456, 0.406],                \n",
    "     std=[0.229, 0.224, 0.225]                  \n",
    "    )])\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    file_path = \"image_files.txt\"  # Changed to the relative path of image_files.txt\n",
    "    with open(file_path, \"r\") as f:\n",
    "        image_files = f.read().splitlines()\n",
    "    \n",
    "    imgs = []\n",
    "    for image_file in image_files:\n",
    "        img = Image.open(image_file).convert(\"RGB\")  # Load the image using the file path\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    return imgs\n",
    "def get_network(name, batch_size):\n",
    "    \"\"\"Get the symbol definition and random weight of a network\"\"\"\n",
    "    input_shape = (batch_size, 3, 224, 224)\n",
    "    output_shape = (batch_size, 1000)\n",
    "\n",
    "    if \"resnet\" in name:\n",
    "        n_layer = int(name.split(\"-\")[1])\n",
    "        if n_layer == 18:\n",
    "            model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1').eval()\n",
    "        elif n_layer == 34:\n",
    "            model = models.resnet34(weights='ResNet34_Weights.IMAGENET1K_V1').eval()\n",
    "        elif n_layer == 50:\n",
    "            model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1').eval()\n",
    "        elif n_layer == 101:\n",
    "            model = models.resnet101(weights='ResNet101_Weights.IMAGENET1K_V1').eval()\n",
    "        elif n_layer == 152:\n",
    "            model = models.resnet152(weights='ResNet152_Weights.IMAGENET1K_V1').eval()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model layers: \" + str(n_layer))\n",
    "\n",
    "    elif \"vgg\" in name:\n",
    "        n_layer = int(name.split(\"-\")[1])\n",
    "        if n_layer == 11:\n",
    "            model = models.vgg11(weights='VGG11_Weights.IMAGENET1K_V1').eval()\n",
    "        elif n_layer == 13:\n",
    "            model = models.vgg13(weights='VGG13_Weights.IMAGENET1K_V1').eval()\n",
    "        elif n_layer == 16:\n",
    "            model = models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1').eval()\n",
    "        elif n_layer == 19:\n",
    "            model = models.vgg19(weights='VGG19_Weights.IMAGENET1K_V1').eval()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model layers: \" + str(n_layer))\n",
    "\n",
    "    elif name == \"mobilenet\":\n",
    "        model = models.mobilenet_v2(weights='MobileNet_V2_Weights.IMAGENET1K_V1').eval()\n",
    "    \n",
    "    elif name == \"squeezenet_v1.1\":\n",
    "        model = models.squeezenet1_1(weights='SqueezeNet1_1_Weights.IMAGENET1K_V1').eval()\n",
    "    \n",
    "    elif name == \"inception_v3\":\n",
    "        input_shape = (batch_size, 3, 299, 299)\n",
    "        model = models.inception_v3(weights='Inception_V3_Weights.IMAGENET1K_V1').eval()\n",
    "    \n",
    "    elif name == \"vit\":\n",
    "        model_path = \"/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tvm_report/model.onnx\"\n",
    "        onnx_model = onnx.load(model_path)\n",
    "        input_names = [input.name for input in onnx_model.graph.input]\n",
    "        print(\"Input names in ONNX model:\", input_names)\n",
    "        shape_dict = {'pixel_values': input_shape}\n",
    "        mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "\n",
    "        return mod, params, input_shape, output_shape\n",
    "        \n",
    " \n",
    "         \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported network: \" + name)\n",
    "    shape_list = [('data', input_shape)]\n",
    "    input_data = torch.randn(input_shape)\n",
    "    scripted_model = torch.jit.trace(model, input_data).eval()\n",
    "    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "\n",
    "    return mod, params, input_shape, output_shape\n",
    "\n",
    "\n",
    "def tune_tasks(\n",
    "    tasks,\n",
    "    measure_option,\n",
    "    tuner=\"xgb_rank_itervar\",\n",
    "    n_trial=1000,\n",
    "    early_stopping=400,\n",
    "    log_filename=\"tuning.log\",\n",
    "    use_transfer_learning=True,\n",
    "):\n",
    "    tmp_log_file = log_filename + \".tmp\"\n",
    "    if os.path.exists(tmp_log_file):\n",
    "        os.remove(tmp_log_file)\n",
    "\n",
    "    for i, tsk in enumerate(reversed(tasks)):\n",
    "        prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "\n",
    "        if tuner == \"xgb\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\")\n",
    "        elif tuner == \"xgb_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"curve\")\n",
    "        elif tuner == \"xgb_rank\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\")\n",
    "        elif tuner == \"xgb_rank_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_rank_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_rank_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"curve\")\n",
    "        elif tuner == \"xgb_rank_binary\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\")\n",
    "        elif tuner == \"xgb_rank_binary_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_rank_binary_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_rank_binary_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"curve\")\n",
    "        elif tuner == \"ga\":\n",
    "            tuner_obj = GATuner(tsk, pop_size=100)\n",
    "        elif tuner == \"random\":\n",
    "            tuner_obj = RandomTuner(tsk)\n",
    "        elif tuner == \"gridsearch\":\n",
    "            tuner_obj = GridSearchTuner(tsk)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid tuner: \" + tuner)\n",
    "\n",
    "        if use_transfer_learning:\n",
    "            if os.path.isfile(tmp_log_file):\n",
    "                tuner_obj.load_history(autotvm.record.load_from_file(tmp_log_file))\n",
    "\n",
    "        tsk_trial = min(n_trial, len(tsk.config_space))\n",
    "        tuner_obj.tune(\n",
    "            n_trial=tsk_trial,\n",
    "            early_stopping=early_stopping,\n",
    "            measure_option=measure_option,\n",
    "            callbacks=[\n",
    "                autotvm.callback.progress_bar(tsk_trial, prefix=prefix),\n",
    "                autotvm.callback.log_to_file(tmp_log_file),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    autotvm.record.pick_best(tmp_log_file, log_filename)\n",
    "    os.remove(tmp_log_file)\n",
    "\n",
    "def tune(tuning_opt, batch_size, model, target_device, db_path, target):\n",
    "    if model_exists_in_db(target_device, model, batch_size, db_path):\n",
    "        print(f\"Model {model} with batch size {batch_size} already exists in the database.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Extract tasks...\")\n",
    "        mod, params, input_shape, output_shape = get_network(model, batch_size)\n",
    "        tasks = autotvm.task.extract_from_program(\n",
    "                mod[\"main\"], target=target, params=params, ops=None\n",
    "        )\n",
    "        log_file = tuning_opt[\"log_filename\"]\n",
    "        log_dir = os.path.dirname(log_file)\n",
    "        if log_dir and not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "        # Ensure the log file exists\n",
    "        if not os.path.isfile(log_file):\n",
    "            Path(log_file).touch()\n",
    "        \n",
    "        print(f\"Start tuning {model} for {target_device} with batch size {batch_size}...\")\n",
    "        tune_tasks(tasks, **tuning_opt)\n",
    "        with autotvm.apply_history_best(log_file):\n",
    "            print(\"Compile...\")\n",
    "            with tvm.transform.PassContext(opt_level=3):\n",
    "                lib = relay.build(mod, target=target, params=params)\n",
    "        serealize_lib_to_database(target_device, model, batch_size, lib, db_path)\n",
    "        return lib\n",
    "        \n",
    "def serealize_lib_to_database(device, network, batch_size, lib, db_path):\n",
    "    lib_path = f'/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tvm_report/automated_database/{device}/{network}/{batch_size}'\n",
    "    os.makedirs(lib_path, exist_ok=True)\n",
    "    temp = tvm.relay.Module()\n",
    "    lib = tvm.IRModule.from_expr(lib)\n",
    "    file_name = \"deploy.so\"\n",
    "    path_lib = os.path.join(lib_path, file_name)\n",
    "    lib.export_library(path_lib)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute('''\n",
    "    INSERT INTO device_models (device, model, batch_size)\n",
    "    VALUES (?, ?, ?)\n",
    "    ''', (device, network, batch_size))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def model_exists_in_db(device, network, batch_size, db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = '''\n",
    "    SELECT COUNT(*) FROM device_models\n",
    "    WHERE device = ? AND model = ? AND batch_size = ?\n",
    "    '''\n",
    "    cursor.execute(query, (device, network, batch_size))\n",
    "    result = cursor.fetchone()[0]\n",
    "\n",
    "    conn.close()\n",
    "    return result > 0\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a4dec-89a9-4cc7-a70d-11db2370a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101a110-fcac-4d2f-9f42-325bd1763739",
   "metadata": {},
   "source": [
    "## Fetch the model\n",
    "The model we are using is basic but functional. Also we are not here for training classification models so we will use the pretrained resnet-18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840780f-72cc-46b7-bfae-db81027e329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_model_and_batch_size(batch_size):\n",
    "    batch_size=batch_size\n",
    "    model_name = \"vit\"\n",
    "    # model_name = \"resnet18\"\n",
    "    # model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
    "    #model = getattr(models, model_name)(pretrained=True)\n",
    "    # model = models.vit_b_16(weights='ViT_B_16_Weights.IMAGENET1K_V1')\n",
    "    # model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "    # model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True , autoshape=False)\n",
    "    # model = models.squeezenet1_1(weights=models.SqueezeNet1_1_Weights.IMAGENET1K_V1)\n",
    "    model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\", torchscript=True)\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model, batch_size\n",
    "\n",
    "def check_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA (GPU) is available.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) is not available. Using CPU instead.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ca37c-ab6b-4b0b-9a20-30fad4db23c9",
   "metadata": {},
   "source": [
    "## Load test images\n",
    "Lets begin by creating some functions that will convert the image to the correct size for resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfbb1a5-c94f-40ec-8758-2f6809f0565e",
   "metadata": {},
   "outputs": [],
   "source": [
    " transform = transforms.Compose([            \n",
    "     transforms.Resize(256),                    \n",
    "     transforms.CenterCrop(224),                \n",
    "     transforms.ToTensor(),                     \n",
    "     transforms.Normalize(                      \n",
    "     mean=[0.485, 0.456, 0.406],                \n",
    "     std=[0.229, 0.224, 0.225]                  \n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb09eb-e6f4-4fca-b457-6ac39093e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_labels(imgs, labels, system):\n",
    "    num_images = len(imgs)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))  # Adjust figsize as needed\n",
    "    \n",
    "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
    "        img = img.squeeze(0)  # Remove the batch dimension if it exists\n",
    "        if(system==\"pytorch\"):\n",
    "            img = img.permute(1, 2, 0)  # Change the image tensor shape from (C, H, W) to (H, W, C)\n",
    "        elif(system==\"tvm\"):\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "        else:\n",
    "            print(\"Wrong System please select tvm or pytorch\")\n",
    "        # Normalize pixel values to [0, 1]\n",
    "        img = img - img.min()\n",
    "        img = img / img.max()\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(label, fontsize=10, pad=5)  # Display label on top of the image\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def load_random_images(batch_size):\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    files = os.listdir(directory)\n",
    "    image_files = [f for f in files if f.endswith('.JPEG')]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory.\")\n",
    "        return None\n",
    "    \n",
    "    imgs = []\n",
    "    chosen_image_files = []\n",
    "    for _ in range(batch_size):\n",
    "        random_image = random.choice(image_files)\n",
    "        img_path = os.path.join(directory, random_image)\n",
    "        chosen_image_files.append(img_path)  # Append the chosen image file path\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    \n",
    "    with open(\"image_files.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(chosen_image_files))\n",
    "    \n",
    "    return imgs\n",
    "\n",
    "def get_images():\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    file_path = \"image_files.txt\"  # Changed to the relative path of image_files.txt\n",
    "    with open(file_path, \"r\") as f:\n",
    "        image_files = f.read().splitlines()\n",
    "    \n",
    "    imgs = []\n",
    "    for image_file in image_files:\n",
    "        img = Image.open(image_file).convert(\"RGB\")  # Load the image using the file path\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    float_imgs=imgs.float()\n",
    "    return float_imgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef2394-f2ca-4452-bc39-cd025e785bb4",
   "metadata": {},
   "source": [
    "## Prepare the classes\n",
    "Functions that print the results of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748f428-d9fa-4d6a-b36d-cdcc89e46804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_class(predictions):\n",
    "    with open('imagenet_classes.txt') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    synsets_to_names = {}\n",
    "    with open('imagenet_synsets.txt') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ', 1)\n",
    "            synsets_to_names[parts[0]] = parts[1]\n",
    "\n",
    "    batch_classes = []\n",
    "    for prediction in predictions:\n",
    "        class_name = synsets_to_names[classes[prediction]]\n",
    "        batch_classes.append(class_name)\n",
    "\n",
    "    return batch_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5760e95b-0d57-4920-8111-ed96f1ccb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timit(func, *args, **kwargs):\n",
    "    timing_number = 10\n",
    "    timing_repeat = 10\n",
    "    \n",
    "    warmup_results = timeit.repeat(lambda: func(*args, **kwargs), repeat=timing_repeat, number=timing_number)\n",
    "    timing_results = timeit.repeat(lambda: func(*args, **kwargs), repeat=timing_repeat, number=timing_number)\n",
    "    \n",
    "    timing_summary = {\n",
    "        \"mean\": sum(timing_results) / len(timing_results),\n",
    "        \"median\": sorted(timing_results)[len(timing_results)//2],\n",
    "        \"std\": np.std(timing_results),\n",
    "    }\n",
    "    \n",
    "    print(\"Timing Summary:\")\n",
    "    print(timing_summary)\n",
    "    return timing_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a3bd118-c84e-4594-b30b-6f57fda2a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pytorch(imgs):\n",
    "    imgs=imgs.to(device)\n",
    "    output = model(imgs)\n",
    "    return output\n",
    "    \n",
    "def process_pytorch(model, batch_size):\n",
    "    imgs = get_images()\n",
    "    print(imgs.shape)\n",
    "    labels = [] \n",
    "    out = run_pytorch(imgs)  \n",
    "    #print(out.shape)\n",
    "    for outputs in out:\n",
    "        _, indices = torch.topk(outputs, 1)\n",
    "        img_labels = prediction_to_class(indices) \n",
    "        labels.append(img_labels)\n",
    "    return imgs, labels\n",
    "\n",
    "# batch_size=50\n",
    "# device = check_device()\n",
    "# model, batch_size = load_model_and_batch_size(batch_size)\n",
    "# model = model.to(device)\n",
    "# load_random_images(batch_size)\n",
    "# imgs, labels = process_pytorch(model, batch_size)\n",
    "# pytime = timit(run_pytorch,imgs)\n",
    "#display_images_with_labels(imgs, labels, \"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a7e9e-423b-4a91-b2e1-0172d5d1e518",
   "metadata": {},
   "source": [
    "## TVM without autotuning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "defaa58d-4c1e-4cd7-aa20-c0f4e1152c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay, autotvm\n",
    "import tvm.relay\n",
    "import tvm.relay.testing\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "from tvm.contrib import graph_executor\n",
    "import tvm.runtime\n",
    "import pickle\n",
    "\n",
    "import torch.utils.dlpack\n",
    "\n",
    "from transformers import ViTModel, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44ef9252-b07c-4c3c-93f9-6205c15ed808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = tvm.target.Target(\"cuda -arch=sm_75\")\n",
    "dev = tvm.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adcd4658-2bee-42f6-89fb-db9d421ed506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/public/misampson/miniconda3/envs/tvm/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\", torchscript=True)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "dummy_image = torch.randn(1, 3, 224, 224)  # Dummy image tensor\n",
    "dummy_input = [dummy_image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81586aad-0497-43fb-9700-741377204a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracing the model\n",
    "traced_model = torch.jit.trace(model, dummy_input)\n",
    "traced_model.eval()\n",
    "for p in traced_model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15571819-b8b6-482d-b18d-98301338f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Move model and data to GPU\n",
    "    model.cuda()\n",
    "    dummy_image = dummy_image.cuda()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error moving model to GPU: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5c13a30-0b27-4abc-9a14-becb74fe21c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/public/misampson/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/target/target.py:375: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ < 700)\n#define __shfl_sync(mask, var, lane, width) \\\n        __shfl((var), (lane), (width))\n\n#define __shfl_down_sync(mask, var, offset, width) \\\n        __shfl_down((var), (offset), (width))\n\n#define __shfl_up_sync(mask, var, offset, width) \\\n        __shfl_up((var), (offset), (width))\n#endif\n\n\n#if (((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 4)) || \\\n     (__CUDACC_VER_MAJOR__ > 11))\n#define TVM_ENABLE_L2_PREFETCH 1\n#else\n#define TVM_ENABLE_L2_PREFETCH 0\n#endif\n\n#ifdef _WIN32\n  using uint = unsigned int;\n  using uchar = unsigned char;\n  using ushort = unsigned short;\n  using int64_t = long long;\n  using uint64_t = unsigned long long;\n#else\n  #define uint unsigned int\n  #define uchar unsigned char\n  #define ushort unsigned short\n  #define int64_t long long\n  #define uint64_t unsigned long long\n#endif\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_3_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_variance_kernel(float* __restrict__ T_multiply_red, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_4_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_tanh_kernel(float* __restrict__ T_tanh, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_2_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(768) tvmgen_default_fused_take_kernel(float* __restrict__ T_take, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem);\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_variance_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_multiply_red);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_multiply_erf_multiply_add_multiply_broadcast_to_reshap_f895a3812fb00bdf__kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))], p0[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = p0[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 6)) % 12) * 12608) + ((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 64)) + (((int)threadIdx.x) & 63))];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_3_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 96; ++k_outer) {\n    __syncthreads();\n    p0_shared[((int)threadIdx.x)] = p0[(((((int)blockIdx.y) * 768) + (k_outer * 8)) + ((int)threadIdx.x))];\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((k_outer * 24576) + (ax1_inner * 3072)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.y) * 3072) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red) {\n  float p0_red_rf[1];\n  float red_buf0[1];\n  p0_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197) {\n      p0_red_rf[0] = (p0_red_rf[0] + p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = p0_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197)) {\n    p0_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float conv2d_nchw[56];\n  __shared__ float pad_temp_shared[43681];\n  __shared__ float p1_shared[48];\n  #pragma unroll\n  for (int ff_init = 0; ff_init < 2; ++ff_init) {\n    #pragma unroll\n    for (int yy_init = 0; yy_init < 2; ++yy_init) {\n      conv2d_nchw[((ff_init * 2) + yy_init)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 28)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 4)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 32)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 8)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 36)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 12)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 40)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 16)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 44)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 20)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 48)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 24)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 52)] = 0.000000e+00f;\n    }\n  }\n  for (int rc_outer = 0; rc_outer < 3; ++rc_outer) {\n    for (int ry_outer = 0; ry_outer < 16; ++ry_outer) {\n      for (int rx_outer = 0; rx_outer < 16; ++rx_outer) {\n        __syncthreads();\n        #pragma unroll\n        for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 261; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n          if (((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) < 3971) {\n            if (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 3641) {\n              pad_temp_shared[(((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)] = p0[(((((rc_outer * 50176) + ((((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) / 19) * 224)) + (ry_outer * 224)) + rx_outer) + ((((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) % 209))];\n            }\n          }\n        }\n        if (((((int)threadIdx.x) >> 2) + ((int)threadIdx.z)) < 12) {\n          if (((int)threadIdx.x) < 4) {\n            p1_shared[((((int)threadIdx.z) * 4) + ((int)threadIdx.x))] = p1[((((((((int)blockIdx.z) * 36864) + (((int)threadIdx.z) * 3072)) + (((int)threadIdx.x) * 768)) + (rc_outer * 256)) + (ry_outer * 16)) + rx_outer)];\n          }\n        }\n        __syncthreads();\n        #pragma unroll\n        for (int ff = 0; ff < 2; ++ff) {\n          #pragma unroll\n          for (int yy = 0; yy < 2; ++yy) {\n            conv2d_nchw[((ff * 2) + yy)] = (conv2d_nchw[((ff * 2) + yy)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 28)] = (conv2d_nchw[(((ff * 2) + yy) + 28)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 4)] = (conv2d_nchw[(((ff * 2) + yy) + 4)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 32)] = (conv2d_nchw[(((ff * 2) + yy) + 32)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 8)] = (conv2d_nchw[(((ff * 2) + yy) + 8)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 36)] = (conv2d_nchw[(((ff * 2) + yy) + 36)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 12)] = (conv2d_nchw[(((ff * 2) + yy) + 12)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 40)] = (conv2d_nchw[(((ff * 2) + yy) + 40)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 16)] = (conv2d_nchw[(((ff * 2) + yy) + 16)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 44)] = (conv2d_nchw[(((ff * 2) + yy) + 44)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 20)] = (conv2d_nchw[(((ff * 2) + yy) + 20)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 48)] = (conv2d_nchw[(((ff * 2) + yy) + 48)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 24)] = (conv2d_nchw[(((ff * 2) + yy) + 24)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 52)] = (conv2d_nchw[(((ff * 2) + yy) + 52)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n          }\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int ax1_inner_inner_inner = 0; ax1_inner_inner_inner < 2; ++ax1_inner_inner_inner) {\n    #pragma unroll\n    for (int ax2_inner_inner_inner = 0; ax2_inner_inner_inner < 2; ++ax2_inner_inner_inner) {\n      T_add[(((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x))] = (conv2d_nchw[((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4704)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 28)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 28)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 4)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4732)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 32)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 56)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 8)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4760)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 36)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 84)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 12)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4788)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 40)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 112)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 16)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4816)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 44)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 140)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 20)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4844)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 48)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 168)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 24)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4872)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 52)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 2; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = __expf((p0[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] - T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_variance_kernel(float* __restrict__ T_multiply_red, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_multiply_red_rf[1];\n  float red_buf0[1];\n  T_multiply_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197) {\n      T_multiply_red_rf[0] = (T_multiply_red_rf[0] + ((p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))] - p1[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))]) * (p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))] - p1[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))])));\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = T_multiply_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197)) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_4_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 384; ++k_outer) {\n    __syncthreads();\n    p0_shared[((int)threadIdx.x)] = p0[(((((int)blockIdx.y) * 3072) + (k_outer * 8)) + ((int)threadIdx.x))];\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((k_outer * 6144) + (ax1_inner * 768)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.y) * 768) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_tanh_kernel(float* __restrict__ T_tanh, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  __shared__ float T_matmul_NT[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[((k_outer * 64) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[0] = ((volatile float*)red_result)[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_tanh[((int)blockIdx.x)] = tanhf((T_matmul_NT[0] + p2[((int)blockIdx.x)]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((((p0[(((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 768) + (((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768))] - p1[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)]) * (1.000000e+00f / sqrtf((p2[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)] + 1.000000e-12f)))) * p3[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p4[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 2; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_softmax_norm[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] / T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (p0[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 6)) % 197) * 768) + ((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 6)) / 197) * 64)) + (((int)threadIdx.x) & 63))] + p1[(((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 6)) / 197) * 64) + (((int)threadIdx.x) & 63))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_add[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((((p0[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] - p1[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)]) * (1.000000e+00f / sqrtf((p2[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)] + 1.000000e-12f)))) * p3[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p4[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 2; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))];\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red) {\n  T_divide[((int)threadIdx.x)] = (p0_red[((int)threadIdx.x)] * 1.302083e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_add[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((p0[(((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 768) + (((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768))] + p1[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p2[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NT_local[1];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[8];\n  float p0_shared_local[1];\n  float p1_shared_local[1];\n  T_batch_matmul_NT_local[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 8; ++k_outer) {\n    __syncthreads();\n    #pragma unroll\n    for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n      p0_shared[ax2_inner] = p0[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (k_outer * 8)) + ax2_inner)];\n    }\n    #pragma unroll\n    for (int ax2_inner_1 = 0; ax2_inner_1 < 8; ++ax2_inner_1) {\n      p1_shared[ax2_inner_1] = p1[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.x) * 64)) + (k_outer * 8)) + ax2_inner_1)];\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      p1_shared_local[0] = p1_shared[k_inner];\n      T_batch_matmul_NT_local[0] = (T_batch_matmul_NT_local[0] + (p0_shared_local[0] * p1_shared_local[0]));\n    }\n  }\n  T_batch_matmul_NT[(((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + ((int)blockIdx.x))] = T_batch_matmul_NT_local[0];\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_2_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 25; ++k_outer) {\n    __syncthreads();\n    if (((k_outer * 8) + ((int)threadIdx.x)) < 197) {\n      p0_shared[((int)threadIdx.x)] = p0[((((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + (k_outer * 8)) + ((int)threadIdx.x))];\n    }\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        if (((k_outer * 8) + ax1_inner) < 197) {\n          p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((((int)blockIdx.z) * 12608) + (k_outer * 512)) + (ax1_inner * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n        }\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      if (((k_outer * 8) + k_inner) < 197) {\n        p0_shared_local[0] = p0_shared[k_inner];\n      }\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n        }\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(768) tvmgen_default_fused_take_kernel(float* __restrict__ T_take, float* __restrict__ p0) {\n  T_take[((int)threadIdx.x)] = p0[((int)threadIdx.x)];\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_ax3_fused_outer = 0; ax0_ax1_fused_ax2_fused_ax3_fused_outer < 2; ++ax0_ax1_fused_ax2_fused_ax3_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_add[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = ((p0[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] * 1.250000e-01f) + p1[((((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 38809)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    float condval;\n    if ((3 <= ((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)))) {\n      condval = p0[((((((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768) * 196) + (((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) + 195) % 196) / 14) * 14)) + (((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) + 13) % 14))];\n    } else {\n      condval = p1[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))];\n    }\n    T_add[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (condval + p2[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem) {\n  if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] + T_softmax_exp[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_variance_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_multiply_red) {\n  T_divide[((int)threadIdx.x)] = (T_multiply_red[((int)threadIdx.x)] * 1.302083e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 96; ++k_outer) {\n    __syncthreads();\n    p0_shared[((int)threadIdx.x)] = p0[(((((int)blockIdx.y) * 768) + (k_outer * 8)) + ((int)threadIdx.x))];\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((k_outer * 6144) + (ax1_inner * 768)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.y) * 768) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_multiply_erf_multiply_add_multiply_broadcast_to_reshap_f895a3812fb00bdf__kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 3; ++ax0_ax1_fused_ax2_fused_outer) {\n    if (((ax0_ax1_fused_ax2_fused_outer * 256) + ((int)blockIdx.x)) < 591) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = ((p0[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 605184)] + p1[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)]) * (5.000000e-01f + (erff(((p0[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 605184)] + p1[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)]) * 7.071068e-01f)) * 5.000000e-01f)));\n    }\n  }\n}\n\n\nCompilation error:\nptxas error   : Entry function 'tvmgen_default_fused_nn_conv2d_add_kernel' uses too much shared data (0x2ab44 bytes, 0xc000 max)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m tvm\u001b[38;5;241m.\u001b[39mrelay\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mte_compiler\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tvm\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mPassContext(opt_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     graph, lib, params \u001b[38;5;241m=\u001b[39m tvm\u001b[38;5;241m.\u001b[39mrelay\u001b[38;5;241m.\u001b[39mbuild(mod_vit, target\u001b[38;5;241m=\u001b[39mtarget,target_host\u001b[38;5;241m=\u001b[39mtarget_host, params\u001b[38;5;241m=\u001b[39mparams_vit)\n\u001b[1;32m     15\u001b[0m module \u001b[38;5;241m=\u001b[39m tvm\u001b[38;5;241m.\u001b[39mcontrib\u001b[38;5;241m.\u001b[39mgraph_runtime\u001b[38;5;241m.\u001b[39mcreate(graph, lib, ctx)\n\u001b[1;32m     17\u001b[0m module\u001b[38;5;241m.\u001b[39mset_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput0\u001b[39m\u001b[38;5;124m\"\u001b[39m, dummy_image_tvm)\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/relay/build_module.py:364\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tophub_context:\n\u001b[1;32m    363\u001b[0m     bld_mod \u001b[38;5;241m=\u001b[39m BuildModule()\n\u001b[0;32m--> 364\u001b[0m     graph_json, runtime_mod, params \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mbuild(\n\u001b[1;32m    365\u001b[0m         mod\u001b[38;5;241m=\u001b[39mir_mod,\n\u001b[1;32m    366\u001b[0m         target\u001b[38;5;241m=\u001b[39mraw_targets,\n\u001b[1;32m    367\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    368\u001b[0m         executor\u001b[38;5;241m=\u001b[39mexecutor,\n\u001b[1;32m    369\u001b[0m         runtime\u001b[38;5;241m=\u001b[39mruntime,\n\u001b[1;32m    370\u001b[0m         workspace_memory_pools\u001b[38;5;241m=\u001b[39mworkspace_memory_pools,\n\u001b[1;32m    371\u001b[0m         constant_memory_pools\u001b[38;5;241m=\u001b[39mconstant_memory_pools,\n\u001b[1;32m    372\u001b[0m         mod_name\u001b[38;5;241m=\u001b[39mmod_name,\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m     func_metadata \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mget_function_metadata()\n\u001b[1;32m    375\u001b[0m     devices \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mget_devices()\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/relay/build_module.py:161\u001b[0m, in \u001b[0;36mBuildModule.build\u001b[0;34m(self, mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m autotvm\u001b[38;5;241m.\u001b[39mGLOBAL_SCOPE\u001b[38;5;241m.\u001b[39msilent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     is_auto_scheduler_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_meta_schedule_enabled() \u001b[38;5;129;01mor\u001b[39;00m old_autotvm_silent\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m mangle_module_name(mod_name)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build(\n\u001b[1;32m    162\u001b[0m     mod,\n\u001b[1;32m    163\u001b[0m     target,\n\u001b[1;32m    164\u001b[0m     target_host,\n\u001b[1;32m    165\u001b[0m     executor,\n\u001b[1;32m    166\u001b[0m     runtime,\n\u001b[1;32m    167\u001b[0m     workspace_memory_pools,\n\u001b[1;32m    168\u001b[0m     constant_memory_pools,\n\u001b[1;32m    169\u001b[0m     mod_name,\n\u001b[1;32m    170\u001b[0m )\n\u001b[1;32m    171\u001b[0m autotvm\u001b[38;5;241m.\u001b[39mGLOBAL_SCOPE\u001b[38;5;241m.\u001b[39msilent \u001b[38;5;241m=\u001b[39m old_autotvm_silent\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Get artifacts\u001b[39;00m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:332\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.PackedFuncBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:277\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./base.pxi:182\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.CHECK_CALL\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/_ffi/base.py:481\u001b[0m, in \u001b[0;36mraise_last_ffi_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m _LIB\u001b[38;5;241m.\u001b[39mTVMDropLastPythonError()\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:56\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.tvm_callback\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/contrib/nvcc.py:204\u001b[0m, in \u001b[0;36mtvm_callback_cuda_compile\u001b[0;34m(code, target)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;129m@tvm\u001b[39m\u001b[38;5;241m.\u001b[39m_ffi\u001b[38;5;241m.\u001b[39mregister_func\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtvm_callback_cuda_compile\u001b[39m(code, target):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"use nvcc to generate fatbin code for better optimization\"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     ptx \u001b[38;5;241m=\u001b[39m compile_cuda(code, target_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfatbin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ptx\n",
      "File \u001b[0;32m~/miniconda3/envs/tvm/lib/python3.11/site-packages/tvm-0.17.dev2+ga64d1f1cc-py3.11-linux-x86_64.egg/tvm/contrib/nvcc.py:128\u001b[0m, in \u001b[0;36mcompile_cuda\u001b[0;34m(code, target_format, arch, options, path_target)\u001b[0m\n\u001b[1;32m    126\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCompilation error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m py_str(out)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    131\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(f\u001b[38;5;241m.\u001b[39mread())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ < 700)\n#define __shfl_sync(mask, var, lane, width) \\\n        __shfl((var), (lane), (width))\n\n#define __shfl_down_sync(mask, var, offset, width) \\\n        __shfl_down((var), (offset), (width))\n\n#define __shfl_up_sync(mask, var, offset, width) \\\n        __shfl_up((var), (offset), (width))\n#endif\n\n\n#if (((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 4)) || \\\n     (__CUDACC_VER_MAJOR__ > 11))\n#define TVM_ENABLE_L2_PREFETCH 1\n#else\n#define TVM_ENABLE_L2_PREFETCH 0\n#endif\n\n#ifdef _WIN32\n  using uint = unsigned int;\n  using uchar = unsigned char;\n  using ushort = unsigned short;\n  using int64_t = long long;\n  using uint64_t = unsigned long long;\n#else\n  #define uint unsigned int\n  #define uchar unsigned char\n  #define ushort unsigned short\n  #define int64_t long long\n  #define uint64_t unsigned long long\n#endif\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_3_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_variance_kernel(float* __restrict__ T_multiply_red, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_4_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_tanh_kernel(float* __restrict__ T_tanh, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_2_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(768) tvmgen_default_fused_take_kernel(float* __restrict__ T_take, float* __restrict__ p0);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem);\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_variance_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_multiply_red);\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_multiply_erf_multiply_add_multiply_broadcast_to_reshap_f895a3812fb00bdf__kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1);\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel(float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = -3.402823e+38f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = max(T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))], p0[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_transpose_reshape_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = p0[((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 6)) % 12) * 12608) + ((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 64)) + (((int)threadIdx.x) & 63))];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_3_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 96; ++k_outer) {\n    __syncthreads();\n    p0_shared[((int)threadIdx.x)] = p0[(((((int)blockIdx.y) * 768) + (k_outer * 8)) + ((int)threadIdx.x))];\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((k_outer * 24576) + (ax1_inner * 3072)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.y) * 3072) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_mean_kernel(float* __restrict__ p0, float* __restrict__ p0_red) {\n  float p0_red_rf[1];\n  float red_buf0[1];\n  p0_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197) {\n      p0_red_rf[0] = (p0_red_rf[0] + p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))]);\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = p0_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197)) {\n    p0_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(168) tvmgen_default_fused_nn_conv2d_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float conv2d_nchw[56];\n  __shared__ float pad_temp_shared[43681];\n  __shared__ float p1_shared[48];\n  #pragma unroll\n  for (int ff_init = 0; ff_init < 2; ++ff_init) {\n    #pragma unroll\n    for (int yy_init = 0; yy_init < 2; ++yy_init) {\n      conv2d_nchw[((ff_init * 2) + yy_init)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 28)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 4)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 32)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 8)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 36)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 12)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 40)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 16)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 44)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 20)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 48)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 24)] = 0.000000e+00f;\n      conv2d_nchw[(((ff_init * 2) + yy_init) + 52)] = 0.000000e+00f;\n    }\n  }\n  for (int rc_outer = 0; rc_outer < 3; ++rc_outer) {\n    for (int ry_outer = 0; ry_outer < 16; ++ry_outer) {\n      for (int rx_outer = 0; rx_outer < 16; ++rx_outer) {\n        __syncthreads();\n        #pragma unroll\n        for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 261; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n          if (((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) < 3971) {\n            if (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 3641) {\n              pad_temp_shared[(((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)] = p0[(((((rc_outer * 50176) + ((((((int)threadIdx.z) * 331) + (((((int)threadIdx.x) * 261) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 11)) / 19) * 224)) + (ry_outer * 224)) + rx_outer) + ((((((int)threadIdx.z) * 3641) + (((int)threadIdx.x) * 261)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) % 209))];\n            }\n          }\n        }\n        if (((((int)threadIdx.x) >> 2) + ((int)threadIdx.z)) < 12) {\n          if (((int)threadIdx.x) < 4) {\n            p1_shared[((((int)threadIdx.z) * 4) + ((int)threadIdx.x))] = p1[((((((((int)blockIdx.z) * 36864) + (((int)threadIdx.z) * 3072)) + (((int)threadIdx.x) * 768)) + (rc_outer * 256)) + (ry_outer * 16)) + rx_outer)];\n          }\n        }\n        __syncthreads();\n        #pragma unroll\n        for (int ff = 0; ff < 2; ++ff) {\n          #pragma unroll\n          for (int yy = 0; yy < 2; ++yy) {\n            conv2d_nchw[((ff * 2) + yy)] = (conv2d_nchw[((ff * 2) + yy)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 28)] = (conv2d_nchw[(((ff * 2) + yy) + 28)] + (pad_temp_shared[((yy * 3344) + (((int)threadIdx.x) * 16))] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 4)] = (conv2d_nchw[(((ff * 2) + yy) + 4)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 32)] = (conv2d_nchw[(((ff * 2) + yy) + 32)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 6688)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 8)] = (conv2d_nchw[(((ff * 2) + yy) + 8)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 36)] = (conv2d_nchw[(((ff * 2) + yy) + 36)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 13376)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 12)] = (conv2d_nchw[(((ff * 2) + yy) + 12)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 40)] = (conv2d_nchw[(((ff * 2) + yy) + 40)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 20064)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 16)] = (conv2d_nchw[(((ff * 2) + yy) + 16)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 44)] = (conv2d_nchw[(((ff * 2) + yy) + 44)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 26752)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 20)] = (conv2d_nchw[(((ff * 2) + yy) + 20)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 48)] = (conv2d_nchw[(((ff * 2) + yy) + 48)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 33440)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n            conv2d_nchw[(((ff * 2) + yy) + 24)] = (conv2d_nchw[(((ff * 2) + yy) + 24)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[((((int)threadIdx.z) * 2) + ff)]));\n            conv2d_nchw[(((ff * 2) + yy) + 52)] = (conv2d_nchw[(((ff * 2) + yy) + 52)] + (pad_temp_shared[(((yy * 3344) + (((int)threadIdx.x) * 16)) + 40128)] * p1_shared[(((((int)threadIdx.z) * 2) + ff) + 24)]));\n          }\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int ax1_inner_inner_inner = 0; ax1_inner_inner_inner < 2; ++ax1_inner_inner_inner) {\n    #pragma unroll\n    for (int ax2_inner_inner_inner = 0; ax2_inner_inner_inner < 2; ++ax2_inner_inner_inner) {\n      T_add[(((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x))] = (conv2d_nchw[((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4704)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 28)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 28)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 4)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4732)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 32)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 56)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 8)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4760)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 36)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 84)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 12)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4788)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 40)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 112)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 16)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4816)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 44)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 140)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 20)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4844)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 48)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 168)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 24)] + p2[(((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner)]);\n      T_add[((((((((int)blockIdx.z) * 9408) + (((int)threadIdx.z) * 392)) + (ax1_inner_inner_inner * 196)) + (ax2_inner_inner_inner * 14)) + ((int)threadIdx.x)) + 4872)] = (conv2d_nchw[(((ax1_inner_inner_inner * 2) + ax2_inner_inner_inner) + 52)] + p2[((((((int)blockIdx.z) * 48) + (((int)threadIdx.z) * 2)) + ax1_inner_inner_inner) + 24)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_1(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ p0) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 2; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = __expf((p0[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] - T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]));\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_variance_kernel(float* __restrict__ T_multiply_red, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_multiply_red_rf[1];\n  float red_buf0[1];\n  T_multiply_red_rf[0] = 0.000000e+00f;\n  for (int k2_outer = 0; k2_outer < 24; ++k2_outer) {\n    if (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197) {\n      T_multiply_red_rf[0] = (T_multiply_red_rf[0] + ((p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))] - p1[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))]) * (p0[((((((int)blockIdx.x) * 24576) + (((int)threadIdx.y) * 768)) + (k2_outer * 32)) + ((int)threadIdx.x))] - p1[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))])));\n    }\n  }\n  uint mask[1];\n  float t0[1];\n  red_buf0[0] = T_multiply_red_rf[0];\n  mask[0] = __activemask();\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 16, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 8, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 4, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 2, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  red_buf0[0] = __shfl_sync(mask[0], red_buf0[0], (((int)threadIdx.y) * 32), 32);\n  if ((((int)threadIdx.x) == 0) && (((((int)blockIdx.x) * 32) + ((int)threadIdx.y)) < 197)) {\n    T_multiply_red[((((int)blockIdx.x) * 32) + ((int)threadIdx.y))] = red_buf0[0];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_4_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 384; ++k_outer) {\n    __syncthreads();\n    p0_shared[((int)threadIdx.x)] = p0[(((((int)blockIdx.y) * 3072) + (k_outer * 8)) + ((int)threadIdx.x))];\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((k_outer * 6144) + (ax1_inner * 768)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.y) * 768) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(64) tvmgen_default_fused_nn_dense_add_tanh_kernel(float* __restrict__ T_tanh, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  float T_matmul_NT_rf[1];\n  __shared__ float red_result[1];\n  __shared__ float T_matmul_NT[1];\n  T_matmul_NT_rf[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 12; ++k_outer) {\n    T_matmul_NT_rf[0] = (T_matmul_NT_rf[0] + (p0[((k_outer * 64) + ((int)threadIdx.x))] * p1[(((((int)blockIdx.x) * 768) + (k_outer * 64)) + ((int)threadIdx.x))]));\n  }\n  float red_buf0[1];\n  uint mask[1];\n  float t0[1];\n  float red_buf0_1[1];\n  uint mask_1[1];\n  float t0_1[1];\n  __shared__ float red_buf_staging[2];\n  red_buf0_1[0] = T_matmul_NT_rf[0];\n  mask_1[0] = __activemask();\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 16, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 8, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 4, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 2, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  t0_1[0] = __shfl_down_sync(mask_1[0], red_buf0_1[0], 1, 32);\n  red_buf0_1[0] = (red_buf0_1[0] + t0_1[0]);\n  if ((((int)threadIdx.x) % 32) == 0) {\n    red_buf_staging[(((int)threadIdx.x) >> 5)] = red_buf0_1[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) < 2) {\n    red_buf0[0] = red_buf_staging[((int)threadIdx.x)];\n  }\n  mask[0] = (__activemask() & (uint)3);\n  t0[0] = __shfl_down_sync(mask[0], red_buf0[0], 1, 32);\n  red_buf0[0] = (red_buf0[0] + t0[0]);\n  if (((int)threadIdx.x) == 0) {\n    ((volatile float*)red_result)[0] = red_buf0[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_matmul_NT[0] = ((volatile float*)red_result)[0];\n  }\n  __syncthreads();\n  if (((int)threadIdx.x) == 0) {\n    T_tanh[((int)blockIdx.x)] = tanhf((T_matmul_NT[0] + p2[((int)blockIdx.x)]));\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_broadcast_to_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((((p0[(((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 768) + (((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768))] - p1[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)]) * (1.000000e+00f / sqrtf((p2[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)] + 1.000000e-12f)))) * p3[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p4[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_3(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem, float* __restrict__ T_softmax_norm) {\n  for (int i0_i1_fused_i2_fused_i3_fused_outer = 0; i0_i1_fused_i2_fused_i3_fused_outer < 2; ++i0_i1_fused_i2_fused_i3_fused_outer) {\n    if ((((i0_i1_fused_i2_fused_i3_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_softmax_norm[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = (T_softmax_exp[(((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] / T_softmax_maxelem[((((i0_i1_fused_i2_fused_i3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) / 197)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_reshape_transpose_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_reshape[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (p0[((((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 6)) % 197) * 768) + ((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 6)) / 197) * 64)) + (((int)threadIdx.x) & 63))] + p1[(((((((int)blockIdx.x) * 16) + (((int)threadIdx.x) >> 6)) / 197) * 64) + (((int)threadIdx.x) & 63))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_subtract_add_rsqrt_multiply_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2, float* __restrict__ p3, float* __restrict__ p4) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_add[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((((p0[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] - p1[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)]) * (1.000000e+00f / sqrtf((p2[(((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3)] + 1.000000e-12f)))) * p3[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p4[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_kernel(float* __restrict__ T_reshape, float* __restrict__ p0) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 2; ++ax0_ax1_fused_ax2_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = p0[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))];\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_mean_kernel_1(float* __restrict__ T_divide, float* __restrict__ p0_red) {\n  T_divide[((int)threadIdx.x)] = (p0_red[((int)threadIdx.x)] * 1.302083e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    T_add[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = ((p0[(((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) * 768) + (((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768))] + p1[(((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768)]) + p2[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void tvmgen_default_fused_nn_batch_matmul_1_kernel(float* __restrict__ T_batch_matmul_NT, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NT_local[1];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[8];\n  float p0_shared_local[1];\n  float p1_shared_local[1];\n  T_batch_matmul_NT_local[0] = 0.000000e+00f;\n  for (int k_outer = 0; k_outer < 8; ++k_outer) {\n    __syncthreads();\n    #pragma unroll\n    for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n      p0_shared[ax2_inner] = p0[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (k_outer * 8)) + ax2_inner)];\n    }\n    #pragma unroll\n    for (int ax2_inner_1 = 0; ax2_inner_1 < 8; ++ax2_inner_1) {\n      p1_shared[ax2_inner_1] = p1[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.x) * 64)) + (k_outer * 8)) + ax2_inner_1)];\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      p1_shared_local[0] = p1_shared[k_inner];\n      T_batch_matmul_NT_local[0] = (T_batch_matmul_NT_local[0] + (p0_shared_local[0] * p1_shared_local[0]));\n    }\n  }\n  T_batch_matmul_NT[(((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + ((int)blockIdx.x))] = T_batch_matmul_NT_local[0];\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_2_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 25; ++k_outer) {\n    __syncthreads();\n    if (((k_outer * 8) + ((int)threadIdx.x)) < 197) {\n      p0_shared[((int)threadIdx.x)] = p0[((((((int)blockIdx.z) * 38809) + (((int)blockIdx.y) * 197)) + (k_outer * 8)) + ((int)threadIdx.x))];\n    }\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        if (((k_outer * 8) + ax1_inner) < 197) {\n          p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((((int)blockIdx.z) * 12608) + (k_outer * 512)) + (ax1_inner * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n        }\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      if (((k_outer * 8) + k_inner) < 197) {\n        p0_shared_local[0] = p0_shared[k_inner];\n      }\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n        }\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        if (((k_outer * 8) + k_inner) < 197) {\n          T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.z) * 12608) + (((int)blockIdx.y) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(768) tvmgen_default_fused_take_kernel(float* __restrict__ T_take, float* __restrict__ p0) {\n  T_take[((int)threadIdx.x)] = p0[((int)threadIdx.x)];\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_multiply_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_ax3_fused_outer = 0; ax0_ax1_fused_ax2_fused_ax3_fused_outer < 2; ++ax0_ax1_fused_ax2_fused_ax3_fused_outer) {\n    if ((((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 65536) + (((int)blockIdx.x) * 256)) + (((int)threadIdx.x) >> 2)) < 116427) {\n      T_add[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = ((p0[(((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] * 1.250000e-01f) + p1[((((ax0_ax1_fused_ax2_fused_ax3_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 38809)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_transpose_concatenate_add_kernel(float* __restrict__ T_add, float* __restrict__ p0, float* __restrict__ p1, float* __restrict__ p2) {\n  if (((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) < 591) {\n    float condval;\n    if ((3 <= ((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)))) {\n      condval = p0[((((((((int)blockIdx.x) * 256) + ((int)threadIdx.x)) % 768) * 196) + (((((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) + 195) % 196) / 14) * 14)) + (((((((int)blockIdx.x) * 4) + (((int)threadIdx.x) >> 8)) / 3) + 13) % 14))];\n    } else {\n      condval = p1[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))];\n    }\n    T_add[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (condval + p2[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))]);\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_nn_softmax_kernel_2(float* __restrict__ T_softmax_exp, float* __restrict__ T_softmax_maxelem) {\n  if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n    T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = 0.000000e+00f;\n  }\n  for (int k = 0; k < 197; ++k) {\n    if (((((int)blockIdx.x) * 256) + (((int)threadIdx.x) >> 2)) < 591) {\n      T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] = (T_softmax_maxelem[((((int)blockIdx.x) * 1024) + ((int)threadIdx.x))] + T_softmax_exp[(((((int)blockIdx.x) * 201728) + (((int)threadIdx.x) * 197)) + k)]);\n    }\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(197) tvmgen_default_fused_variance_kernel_1(float* __restrict__ T_divide, float* __restrict__ T_multiply_red) {\n  T_divide[((int)threadIdx.x)] = (T_multiply_red[((int)threadIdx.x)] * 1.302083e-03f);\n}\n\nextern \"C\" __global__ void __launch_bounds__(8) tvmgen_default_fused_nn_batch_matmul_kernel(float* __restrict__ T_batch_matmul_NN, float* __restrict__ p0, float* __restrict__ p1) {\n  float T_batch_matmul_NN_local[8];\n  __shared__ float p0_shared[8];\n  __shared__ float p1_shared[512];\n  float p0_shared_local[1];\n  float p1_shared_local[8];\n  for (int j_c_init = 0; j_c_init < 8; ++j_c_init) {\n    T_batch_matmul_NN_local[j_c_init] = 0.000000e+00f;\n  }\n  for (int k_outer = 0; k_outer < 96; ++k_outer) {\n    __syncthreads();\n    p0_shared[((int)threadIdx.x)] = p0[(((((int)blockIdx.y) * 768) + (k_outer * 8)) + ((int)threadIdx.x))];\n    for (int ax1_inner = 0; ax1_inner < 8; ++ax1_inner) {\n      #pragma unroll\n      for (int ax2_inner = 0; ax2_inner < 8; ++ax2_inner) {\n        p1_shared[(((ax1_inner * 64) + (((int)threadIdx.x) * 8)) + ax2_inner)] = p1[(((((k_outer * 6144) + (ax1_inner * 768)) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + ax2_inner)];\n      }\n    }\n    __syncthreads();\n    for (int k_inner = 0; k_inner < 8; ++k_inner) {\n      p0_shared_local[0] = p0_shared[k_inner];\n      #pragma unroll\n      for (int ax2 = 0; ax2 < 8; ++ax2) {\n        p1_shared_local[ax2] = p1_shared[(((k_inner * 64) + (((int)threadIdx.x) * 8)) + ax2)];\n      }\n      #pragma unroll\n      for (int j_c = 0; j_c < 8; ++j_c) {\n        T_batch_matmul_NN_local[j_c] = (T_batch_matmul_NN_local[j_c] + (p0_shared_local[0] * p1_shared_local[j_c]));\n      }\n    }\n  }\n  #pragma unroll\n  for (int j_inner_inner = 0; j_inner_inner < 8; ++j_inner_inner) {\n    T_batch_matmul_NN[((((((int)blockIdx.y) * 768) + (((int)blockIdx.x) * 64)) + (((int)threadIdx.x) * 8)) + j_inner_inner)] = T_batch_matmul_NN_local[j_inner_inner];\n  }\n}\n\nextern \"C\" __global__ void __launch_bounds__(1024) tvmgen_default_fused_reshape_squeeze_add_multiply_erf_multiply_add_multiply_broadcast_to_reshap_f895a3812fb00bdf__kernel(float* __restrict__ T_reshape, float* __restrict__ p0, float* __restrict__ p1) {\n  for (int ax0_ax1_fused_ax2_fused_outer = 0; ax0_ax1_fused_ax2_fused_outer < 3; ++ax0_ax1_fused_ax2_fused_outer) {\n    if (((ax0_ax1_fused_ax2_fused_outer * 256) + ((int)blockIdx.x)) < 591) {\n      T_reshape[(((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x))] = ((p0[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 605184)] + p1[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)]) * (5.000000e-01f + (erff(((p0[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 605184)] + p1[((((ax0_ax1_fused_ax2_fused_outer * 262144) + (((int)blockIdx.x) * 1024)) + ((int)threadIdx.x)) % 3072)]) * 7.071068e-01f)) * 5.000000e-01f)));\n    }\n  }\n}\n\n\nCompilation error:\nptxas error   : Entry function 'tvmgen_default_fused_nn_conv2d_add_kernel' uses too much shared data (0x2ab44 bytes, 0xc000 max)\n"
     ]
    }
   ],
   "source": [
    "shape_list = [(i.debugName().split('.')[0], i.type().sizes()) for i in list(traced_model.graph.inputs())[1:]]\n",
    "mod_vit, params_vit = tvm.relay.frontend.from_pytorch(traced_model, shape_list, default_dtype=\"float32\")\n",
    "\n",
    "# target = tvm.target.cuda\n",
    "target = tvm.target.Target(\"cuda -arch=sm_75\")\n",
    "ctx = tvm.cuda(0)\n",
    "dummy_image_np = dummy_image.cpu().numpy()\n",
    "dummy_image_tvm = tvm.nd.array(dummy_image_np, ctx)\n",
    "# tvm.relay.backend.compile_engine.get().clear()\n",
    "tvm.relay.backend.te_compiler.get().clear()\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    graph, lib, params = tvm.relay.build(mod_vit, target=target, params=params_vit)\n",
    "\n",
    "module = tvm.contrib.graph_runtime.create(graph, lib, ctx)\n",
    "\n",
    "module.set_input(\"input0\", dummy_image_tvm)\n",
    "module.set_input(**params)\n",
    "module.run()\n",
    "output = module.get_output(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0f188-64ef-4dbe-96db-ed918719b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pt = model(dummy_image)\n",
    "(numpy.abs((res_pt[0].cpu().numpy() - output.asnumpy())).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0a2fd-07b7-4655-afe9-c8560725459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvm_wo_autotune_time=timit(run_module,module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8625338-ccbd-4e01-b058-cb45e5ad64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def execute_and_plot_tvm_timit():\n",
    "    global tvm_lib, tvm_inp_name\n",
    "    batch_sizes = [1, 10, 100, 200, 256]\n",
    "    timing_results = []\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        #we want to enter relay for each batch\n",
    "        tvm_lib = None\n",
    "        tvm_inp_name = None\n",
    "        load_random_images(batch_size)\n",
    "        model, batch_size = load_model_and_batch_size(batch_size)\n",
    "        imgs,classes, module=run_tvm(get_images(),batch_size)\n",
    "        tvm_wo_autotune_time=timit(run_module,module)\n",
    "        mean_time = tvm_wo_autotune_time[\"mean\"]\n",
    "        save_mean_time(batch_size, mean_time)\n",
    "\n",
    "    timing_results = get_timing_results(batch_sizes)  # Retrieve timing results from saved files\n",
    "    plot_timing_results(timing_results)\n",
    "\n",
    "\n",
    "def save_mean_time(batch_size, mean_time):\n",
    "    with open(f'tvm_timing_batch_{batch_size}.txt', 'w') as f:\n",
    "        f.write(str(mean_time))\n",
    "\n",
    "def get_timing_results(batch_sizes):\n",
    "    timing_results = []\n",
    "    for batch_size in batch_sizes:\n",
    "        with open(f'tvm_timing_batch_{batch_size}.txt', 'r') as f:\n",
    "            mean_time = float(f.read())\n",
    "        timing_results.append((batch_size, mean_time))\n",
    "    return timing_results\n",
    "\n",
    "def plot_timing_results(timing_results):\n",
    "    # Remove None values from timing_results\n",
    "    timing_results = [result for result in timing_results if result is not None]\n",
    "\n",
    "    if not timing_results:\n",
    "        print(\"No timing results to plot.\")\n",
    "        return\n",
    "\n",
    "    timing_results.sort(key=lambda x: x[1])  # Sort by mean time\n",
    "    batch_sizes = [result[0] for result in timing_results]  # Extract batch sizes\n",
    "    timing_means = [result[1] for result in timing_results]  # Extract timing results\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Generate equally spaced y-axis ticks\n",
    "    y_ticks = np.arange(len(batch_sizes))\n",
    "\n",
    "    # Plot horizontal bars for mean timing results\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(batch_sizes)))  # Generate different colors\n",
    "    for i, (mean, size) in enumerate(zip(timing_means, batch_sizes)):\n",
    "        plt.barh(y_ticks[i], mean, color=colors[i], label=f'Batch Size {size}')\n",
    "\n",
    "    # Set y-axis ticks and labels\n",
    "    plt.yticks(y_ticks, batch_sizes)\n",
    "\n",
    "    plt.title('PyTorch Mean Execution Time vs Batch Size')\n",
    "    plt.xlabel('Mean Execution Time (seconds)')\n",
    "    plt.ylabel('Batch Size')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)  # Remove background grid lines\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the smallest batch size at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "#execute_and_plot_tvm_timit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ba971-ff62-4fcd-83e3-763da64bdf84",
   "metadata": {},
   "source": [
    "## Begin TVM steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e98749-f869-42b2-a4c1-b7ed537a1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm.relay.testing\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "import tvm.auto_scheduler as auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3e9eb-f5d5-4993-85b8-8aef35a4339e",
   "metadata": {},
   "source": [
    "## Define Network\n",
    "First we need to define the network in relay frontend API.\n",
    "We can load some pre-defined network from :code:`tvm.relay.testing`.\n",
    "We can also load models from MXNet, ONNX and TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dba6e1-970a-4f9e-8570-2c095238a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(name, batch_size):\n",
    "    \"\"\"Get the symbol definition and random weight of a network\"\"\"\n",
    "    input_shape = (batch_size, 3, 224, 224)\n",
    "    output_shape = (batch_size, 1000)\n",
    "\n",
    "    if \"resnet\" in name:\n",
    "        n_layer = int(name.split(\"-\")[1])\n",
    "        mod, params = relay.testing.resnet.get_workload(\n",
    "            num_layers=n_layer, batch_size=batch_size, dtype=dtype\n",
    "        )\n",
    "    elif \"vgg\" in name:\n",
    "        n_layer = int(name.split(\"-\")[1])\n",
    "        mod, params = relay.testing.vgg.get_workload(\n",
    "            num_layers=n_layer, batch_size=batch_size, dtype=dtype\n",
    "        )\n",
    "    elif name == \"mobilenet\":\n",
    "        mod, params = relay.testing.mobilenet.get_workload(batch_size=batch_size, dtype=dtype)\n",
    "    elif name == \"squeezenet_v1.1\":\n",
    "        mod, params = relay.testing.squeezenet.get_workload(\n",
    "            batch_size=batch_size, version=\"1.1\", dtype=dtype\n",
    "        )\n",
    "    elif name == \"inception_v3\":\n",
    "        input_shape = (batch_size, 3, 299, 299)\n",
    "        mod, params = relay.testing.inception_v3.get_workload(batch_size=batch_size, dtype=dtype)\n",
    "    elif name == \"mxnet\":\n",
    "        # an example for mxnet model\n",
    "        from mxnet.gluon.model_zoo.vision import get_model\n",
    "\n",
    "        block = get_model(\"resnet18_v1\", pretrained=True)\n",
    "        mod, params = relay.frontend.from_mxnet(block, shape={\"data\": input_shape}, dtype=dtype)\n",
    "        net = mod[\"main\"]\n",
    "        net = relay.Function(\n",
    "            net.params, relay.nn.softmax(net.body), None, net.type_params, net.attrs\n",
    "        )\n",
    "        mod = tvm.IRModule.from_expr(net)\n",
    "    elif name == \"vit\":\n",
    "        model_path = \"/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tvm_report/model.onnx\"\n",
    "        onnx_model = onnx.load(model_path)\n",
    "        input_names = [input.name for input in onnx_model.graph.input]\n",
    "        print(\"Input names in ONNX model:\", input_names)\n",
    "        shape_dict = {'pixel_values': input_shape}\n",
    "        mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "        return mod, params, input_shape, output_shape\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported network: \" + name)\n",
    "\n",
    "    return mod, params, input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb9a1b-1f78-4956-ae90-e9555e15fd8d",
   "metadata": {},
   "source": [
    "## Set Tuning Options\n",
    "Before tuning, we apply some configurations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ea002-ac1a-4021-a9ac-f628350237dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEVICE CONFIG ####\n",
    "target = tvm.target.cuda()\n",
    "\n",
    "#### TUNING OPTION ####\n",
    "network = \"squeezenet_v1.1\"\n",
    "log_file = \"%s.log\" % network\n",
    "dtype = \"float32\"\n",
    "\n",
    "tuning_option = {\n",
    "    \"log_filename\": log_file,\n",
    "    \"tuner\": \"xgb\",\n",
    "    \"n_trial\": 2000,\n",
    "    \"early_stopping\": 2,\n",
    "    \"measure_option\": autotvm.measure_option(\n",
    "        builder=autotvm.LocalBuilder(timeout=10),\n",
    "        runner=autotvm.LocalRunner(number=4, repeat=1, timeout=4, min_repeat_ms=150),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a49ca3-8969-42e3-bf98-23314fadbbbb",
   "metadata": {},
   "source": [
    "## Begin Tuning\n",
    "Now we can extract tuning tasks from the network and begin tuning.\n",
    "Here, we provide a simple utility function to tune a list of tasks.\n",
    "This function is just an initial implementation which tunes them in sequential order.\n",
    "We will introduce a more sophisticated tuning scheduler in the future.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0b96d-f1e3-4328-9efd-3b23ebd6d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can skip the implementation of this function for this tutorial.\n",
    "def tune_tasks(\n",
    "    tasks,\n",
    "    measure_option,\n",
    "    tuner=\"xgb\",\n",
    "    n_trial=1000,\n",
    "    early_stopping=2,\n",
    "    log_filename=\"tuning.log\",\n",
    "    use_transfer_learning=True,\n",
    "):\n",
    "    # create tmp log file\n",
    "    tmp_log_file = log_filename + \".tmp\"\n",
    "    if os.path.exists(tmp_log_file):\n",
    "        os.remove(tmp_log_file)\n",
    "\n",
    "    for i, tsk in enumerate(reversed(tasks)):\n",
    "        prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "\n",
    "        # create tuner\n",
    "        if tuner == \"xgb\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\")\n",
    "        elif tuner == \"xgb_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"curve\")\n",
    "        elif tuner == \"xgb_rank\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\")\n",
    "        elif tuner == \"xgb_rank_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_rank_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_rank_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"curve\")\n",
    "        elif tuner == \"xgb_rank_binary\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\")\n",
    "        elif tuner == \"xgb_rank_binary_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_rank_binary_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_rank_binary_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"curve\")\n",
    "        elif tuner == \"ga\":\n",
    "            tuner_obj = GATuner(tsk, pop_size=100)\n",
    "        elif tuner == \"random\":\n",
    "            tuner_obj = RandomTuner(tsk)\n",
    "        elif tuner == \"gridsearch\":\n",
    "            tuner_obj = GridSearchTuner(tsk)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid tuner: \" + tuner)\n",
    "\n",
    "        if use_transfer_learning:\n",
    "            if os.path.isfile(tmp_log_file):\n",
    "                tuner_obj.load_history(autotvm.record.load_from_file(tmp_log_file))\n",
    "\n",
    "        # do tuning\n",
    "        tsk_trial = min(n_trial, len(tsk.config_space))\n",
    "        tuner_obj.tune(\n",
    "            n_trial=tsk_trial,\n",
    "            early_stopping=early_stopping,\n",
    "            measure_option=measure_option,\n",
    "            callbacks=[\n",
    "                autotvm.callback.progress_bar(tsk_trial, prefix=prefix),\n",
    "                autotvm.callback.log_to_file(tmp_log_file),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # pick best records to a cache file\n",
    "    autotvm.record.pick_best(tmp_log_file, log_filename)\n",
    "    os.remove(tmp_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e2181-3ca0-4467-9a76-ef08beb52e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate(tuning_opt,batch_size):\n",
    "    # extract workloads from relay program\n",
    "    print(\"Extract tasks...\")\n",
    "    mod, params, input_shape, out_shape = get_network(network, batch_size)\n",
    "    tasks = autotvm.task.extract_from_program(\n",
    "        mod[\"main\"], target=target, params=params, ops=(relay.op.get(\"nn.conv2d\"),)\n",
    "    )\n",
    "\n",
    "    # run tuning tasks\n",
    "    print(\"Tuning...\")\n",
    "    tune_tasks(tasks, **tuning_opt)\n",
    "\n",
    "    # compile kernels with history best records\n",
    "    with autotvm.apply_history_best(log_file):\n",
    "        print(\"Compile...\")\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = relay.build_module.build(mod, target=target, params=params)\n",
    "\n",
    "        # load parameters\n",
    "        dev = tvm.device(str(target), 0)\n",
    "        module = runtime.GraphModule(lib[\"default\"](dev))\n",
    "        data_tvm = tvm.nd.array((np.random.uniform(size=input_shape)).astype(dtype))\n",
    "        module.set_input(\"data\", data_tvm)\n",
    "\n",
    "        # evaluate\n",
    "        print(\"Evaluate inference time cost...\")\n",
    "        print(module.benchmark(dev, number=1, repeat=600))\n",
    "        \n",
    "    return module\n",
    "# We do not run the tuning in our webpage server since it takes too long.\n",
    "# Uncomment the following line to run it by yourself.\n",
    "module =tune_and_evaluate(tuning_option,batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05d796-1847-4853-95d6-90d9341d98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvm_relay_with_file(network, batch_size):\n",
    "    tuning_logs_dir = \"/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tuning-logs\"\n",
    "    log_dir = f\"log{batch_size}\"\n",
    "    logfile_path = os.path.join(tuning_logs_dir, \"tune_nn/longer-tune\", log_dir, \"resnet-18.log\")\n",
    "    \n",
    "    mod, params, input_shape, out_shape = get_network(network, batch_size)\n",
    "    \n",
    "    with autotvm.apply_history_best(logfile_path):\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = relay.build(mod, target=target, params=params)\n",
    "    \n",
    "    # Load the compiled module onto the device\n",
    "    dev = tvm.device(str(target), 0)\n",
    "    module = runtime.GraphModule(lib[\"default\"](dev))\n",
    "    return module\n",
    "\n",
    "def save_mean_time(batch_size, mean_time):\n",
    "    with open(f'autotune_all_timing_batch_{batch_size}.txt', 'w') as f:\n",
    "        f.write(str(mean_time))\n",
    "\n",
    "def get_timing_results(batch_sizes):\n",
    "    timing_results = []\n",
    "    for batch_size in batch_sizes:\n",
    "        with open(f'autotune_all_timing_batch_{batch_size}.txt', 'r') as f:\n",
    "            mean_time = float(f.read())\n",
    "        timing_results.append((batch_size, mean_time))\n",
    "    return timing_results\n",
    "    \n",
    "batch_size=256\n",
    "# module = tvm_relay_with_file(network, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb6ee5-23e0-4058-8663-704d7cf91c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " tvm_wo_autotune_time=timit(run_module,module)\n",
    "# mean_time = tvm_wo_autotune_time[\"mean\"]\n",
    "# save_mean_time(batch_size, mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a22145-db20-4f2b-8a00-3760389ff38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def execute_and_plot_autotune_timit():\n",
    "    global tvm_lib, tvm_inp_name\n",
    "    batch_sizes = [1, 10, 100, 200, 256]\n",
    "    timing_results = []\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        module = tvm_relay_with_file(network, batch_size)\n",
    "        tvm_wo_autotune_time=timit(run_module,module)\n",
    "        mean_time = tvm_wo_autotune_time[\"mean\"]\n",
    "        save_mean_time(batch_size, mean_time)\n",
    "\n",
    "    timing_results = get_timing_results(batch_sizes)  # Retrieve timing results from saved files\n",
    "    plot_timing_results(timing_results)\n",
    "\n",
    "\n",
    "def save_mean_time(batch_size, mean_time):\n",
    "    with open(f'autotune_timing_batch_{batch_size}.txt', 'w') as f:\n",
    "        f.write(str(mean_time))\n",
    "\n",
    "def get_timing_results(batch_sizes):\n",
    "    timing_results = []\n",
    "    for batch_size in batch_sizes:\n",
    "        with open(f'autotune_timing_batch_{batch_size}.txt', 'r') as f:\n",
    "            mean_time = float(f.read())\n",
    "        timing_results.append((batch_size, mean_time))\n",
    "    return timing_results\n",
    "\n",
    "def plot_timing_results(timing_results):\n",
    "    # Remove None values from timing_results\n",
    "    timing_results = [result for result in timing_results if result is not None]\n",
    "\n",
    "    if not timing_results:\n",
    "        print(\"No timing results to plot.\")\n",
    "        return\n",
    "\n",
    "    timing_results.sort(key=lambda x: x[1])  # Sort by mean time\n",
    "    batch_sizes = [result[0] for result in timing_results]  # Extract batch sizes\n",
    "    timing_means = [result[1] for result in timing_results]  # Extract timing results\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Generate equally spaced y-axis ticks\n",
    "    y_ticks = np.arange(len(batch_sizes))\n",
    "\n",
    "    # Plot horizontal bars for mean timing results\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(batch_sizes)))  # Generate different colors\n",
    "    for i, (mean, size) in enumerate(zip(timing_means, batch_sizes)):\n",
    "        plt.barh(y_ticks[i], mean, color=colors[i], label=f'Batch Size {size}')\n",
    "\n",
    "    # Set y-axis ticks and labels\n",
    "    plt.yticks(y_ticks, batch_sizes)\n",
    "\n",
    "    plt.title('PyTorch Mean Execution Time vs Batch Size')\n",
    "    plt.xlabel('Mean Execution Time (seconds)')\n",
    "    plt.ylabel('Batch Size')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)  # Remove background grid lines\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the smallest batch size at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "#execute_and_plot_autotune_timit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56dcd3-d227-4381-a528-51c3525df91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc45d64-5d0c-4eb6-8fe9-572df635d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvm_autotune_time=timit(run_module,module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99debf49-5ece-4d5d-aa5b-1133874ed815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timestamps(time1, time2, time3):\n",
    "    # Parse the timestamps to extract mean, median, and standard deviation values\n",
    "    def parse_timestamp(timestamp):\n",
    "        if timestamp is None:\n",
    "            return None, None, None\n",
    "        return timestamp[\"mean\"], timestamp[\"median\"], timestamp[\"std\"]\n",
    "\n",
    "    t1_mean, t1_median, t1_std = parse_timestamp(time1)\n",
    "    t2_mean, t2_median, t2_std = parse_timestamp(time2)\n",
    "    t3_mean, t3_median, t3_std = parse_timestamp(time3)\n",
    "\n",
    "    # Plotting\n",
    "    labels = ['Mean', 'Median', 'Std']\n",
    "    t1_values = [t1_mean, t1_median, t1_std]\n",
    "    t2_values = [t2_mean, t2_median, t2_std]\n",
    "    t3_values = [t3_mean, t3_median, t3_std]\n",
    "\n",
    "    x = range(len(labels))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bars = []\n",
    "    \n",
    "    if t1_mean is not None:\n",
    "        bars.append(ax.bar(x, t1_values, width, label='Pytorch'))\n",
    "    if t2_mean is not None:\n",
    "        bars.append(ax.bar([i + width for i in x], t2_values, width, label='TVM without tuning'))\n",
    "    if t3_mean is not None:\n",
    "        bars.append(ax.bar([i + width*2 for i in x], t3_values, width, label='TVM autotune'))\n",
    "\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Time')\n",
    "    ax.set_title('Classification Timing Comparison')\n",
    "    ax.set_xticks([i + width for i in x])\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    # Add legend only if there are bars plotted\n",
    "    if bars:\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fb8e9-fa39-4c5f-adb9-da43839f2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timestamps(pytorch_time, tvm_wo_autotune_time, tvm_autotune_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b017-84ab-4aae-92a6-34e05091a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_timestamps(time1, time2, time3):\n",
    "    # Parse the timestamps to extract mean values\n",
    "    def parse_timestamp(timestamp):\n",
    "        if timestamp is None:\n",
    "            return None\n",
    "        return timestamp[\"mean\"]\n",
    "\n",
    "    t1_mean = parse_timestamp(time1)\n",
    "    t2_mean = parse_timestamp(time2)\n",
    "    t3_mean = parse_timestamp(time3)\n",
    "\n",
    "    # Plotting\n",
    "    labels = ['Pytorch', 'TVM without tuning', 'TVM autotune']\n",
    "    means = [t1_mean, t2_mean, t3_mean]\n",
    "\n",
    "    x = range(len(labels))\n",
    "    width = 0.5\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bars = []\n",
    "\n",
    "    if t1_mean is not None:\n",
    "        bars.append(ax.bar(x[0], t1_mean, width, label='Pytorch'))\n",
    "    if t2_mean is not None:\n",
    "        bars.append(ax.bar(x[1], t2_mean, width, label='TVM without tuning'))\n",
    "    if t3_mean is not None:\n",
    "        bars.append(ax.bar(x[2], t3_mean, width, label='TVM autotune'))\n",
    "\n",
    "    ax.set_xlabel('Frameworks')\n",
    "    ax.set_ylabel('Mean Time')\n",
    "    ax.set_title('Mean Classification Time Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    # Add the mean value on top of each bar\n",
    "    for bar in bars:\n",
    "        for b in bar:\n",
    "            height = b.get_height()\n",
    "            ax.annotate(f'{height:.4f}',\n",
    "                        xy=(b.get_x() + b.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2896b-3813-4497-8dca-dd96a0a257dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_timestamps(pytorch_time, tvm_wo_autotune_time, tvm_autotune_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4478cf3-716d-4b73-956b-30f3650b4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_timing_results(file_prefixes, batch_sizes):\n",
    "    timing_results_list = []\n",
    "    for file_prefix in file_prefixes:\n",
    "        timing_results = []\n",
    "        for batch_size in batch_sizes:\n",
    "            file_path = f'{file_prefix}{batch_size}.txt'\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    mean_time = float(f.read())\n",
    "                timing_results.append((batch_size, mean_time))\n",
    "            except FileNotFoundError:\n",
    "                pass  # Skip if file not found for the current batch size\n",
    "        timing_results_list.append(timing_results)\n",
    "    return timing_results_list\n",
    "\n",
    "def plot_timing_results(timing_results_list, labels, model, dataset):\n",
    "    if not timing_results_list or not labels:\n",
    "        print(\"No timing results or labels provided.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))  # Adjust figsize if needed\n",
    "\n",
    "    # Generate equally spaced x-axis ticks\n",
    "    x_ticks = np.arange(len(timing_results_list[0]))\n",
    "    \n",
    "    # Define colors for PyTorch, TVM, and autotune\n",
    "    color_map = {'PyTorch': 'orange', 'TVM': 'lightblue', 'Autotune': 'darkblue'}\n",
    "    \n",
    "    # Plot vertical bars for mean timing results\n",
    "    for i, (timing_results, label) in enumerate(zip(timing_results_list, labels)):\n",
    "        timing_means = [result[1] for result in timing_results]\n",
    "        batch_sizes = [result[0] for result in timing_results]\n",
    "        \n",
    "        for j, (mean, size) in enumerate(zip(timing_means, batch_sizes)):\n",
    "            plt.bar(x_ticks[j] + i * 0.2, mean, color=color_map.get(label, 'black'), width=0.2)\n",
    "            #plt.text(x_ticks[j] + i * 0.2, mean, f'{mean:.3f}s', ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "    # Set x-axis ticks and labels\n",
    "    if 256 in batch_sizes:\n",
    "        batch_sizes = [size for size in batch_sizes if size != 256] + [256]  # Move batch size 256 to the end\n",
    "    plt.xticks(x_ticks + 0.2 * len(timing_results_list) / 2, batch_sizes, fontsize=12)\n",
    "\n",
    "    plt.title('Execution on Nvidia GPU 2080ti', fontsize=36)\n",
    "    plt.xlabel('Batch Size', fontsize=24)\n",
    "    plt.ylabel('Mean Execution Time (seconds)', fontsize=24)\n",
    "    \n",
    "    # Define custom legend labels and handles with corresponding colors\n",
    "    custom_handles = [plt.Rectangle((0,0),1,1, color=color_map[label]) for label in labels]\n",
    "    custom_labels = labels\n",
    "    \n",
    "    # Display legend with custom labels and handles\n",
    "    plt.legend(custom_handles, custom_labels, loc='upper left', fontsize=12)\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "file_prefixes = ['pytorch_timing_batch_', 'tvm_timing_batch_', 'autotune_timing_batch_']\n",
    "labels = ['PyTorch', 'TVM', 'Autotune']\n",
    "batch_sizes = [1, 10, 100, 200, 256] \n",
    "timing_results_list = get_timing_results(file_prefixes, batch_sizes)\n",
    "plot_timing_results(timing_results_list, labels, model='ResNet-18', dataset='ImageNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5173e04-da27-4e2d-a061-5f9548c4d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_timing_results(file_prefixes, batch_size):\n",
    "    timing_results_list = []\n",
    "    for file_prefix in file_prefixes:\n",
    "        file_path = f'{file_prefix}{batch_size}.txt'\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                mean_time = float(f.read())\n",
    "            timing_results_list.append((batch_size, mean_time))\n",
    "        except FileNotFoundError:\n",
    "            timing_results_list.append((batch_size, None))  # Use None for missing values\n",
    "    return timing_results_list\n",
    "\n",
    "def plot_timing_results(timing_results_list, labels, model, dataset):\n",
    "    if not timing_results_list or not labels:\n",
    "        print(\"No timing results or labels provided.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))  # Adjust figsize if needed\n",
    "\n",
    "    # Define colors for PyTorch, TVM, Autotune, and Autotune_all\n",
    "    color_map = {'PyTorch': 'orange', 'TVM': 'lightblue', 'Autotune': 'darkblue', 'Autotune_all': 'purple'}\n",
    "    \n",
    "    # Plot vertical bars for mean timing results\n",
    "    batch_size, _ = timing_results_list[0]  # All results should have the same batch size\n",
    "    x_ticks = np.arange(1)  # Only one batch size\n",
    "\n",
    "    # Set bar width and spacing\n",
    "    bar_width = 0.05  # Thinner bars\n",
    "    spacing = 0.02  # Less spacing\n",
    "\n",
    "    for i, ((_, mean), label) in enumerate(zip(timing_results_list, labels)):\n",
    "        if mean is not None:  # Only plot if mean is available\n",
    "            plt.bar(x_ticks + i * (bar_width + spacing), mean, color=color_map.get(label, 'black'), width=bar_width)\n",
    "            plt.text(x_ticks + i * (bar_width + spacing), mean, f'{mean:.3f}s', ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "    # Set x-axis ticks and labels\n",
    "    plt.xticks([0.1], [batch_size], fontsize=12)  # Adjust position to align with thinner bars\n",
    "\n",
    "    plt.title('Execution on Nvidia GPU 2080ti', fontsize=36)\n",
    "    plt.xlabel('Batch Size', fontsize=24)\n",
    "    plt.ylabel('Mean Execution Time (seconds)', fontsize=24)\n",
    "    \n",
    "    # Define custom legend labels and handles with corresponding colors\n",
    "    custom_handles = [plt.Rectangle((0,0),1,1, color=color_map[label]) for label in labels]\n",
    "    custom_labels = ['PyTorch', 'TVM', 'Autotune_conv2d', 'Autotune_all']  # Updated legend label\n",
    "    \n",
    "    # Display legend with custom labels and handles\n",
    "    plt.legend(custom_handles, custom_labels, loc='upper left', fontsize=12)\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "file_prefixes = ['pytorch_timing_batch_', 'tvm_timing_batch_', 'autotune_timing_batch_', 'autotune_all_timing_batch_']\n",
    "labels = ['PyTorch', 'TVM', 'Autotune', 'Autotune_all']\n",
    "batch_size = 256 \n",
    "timing_results_list = get_timing_results(file_prefixes, batch_size)\n",
    "plot_timing_results(timing_results_list, labels, model='ResNet-18', dataset='ImageNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c0118-20ba-4955-9dbb-14b074fa42e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778aa7a-3b8a-4961-8aaf-39309d3da397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvm_relay_with_file(network, batch_size, logfile_path):\n",
    "    mod, params, input_shape, out_shape = get_network(network, batch_size)\n",
    "    if logfile_path:\n",
    "        with autotvm.apply_history_best(logfile_path):\n",
    "            with tvm.transform.PassContext(opt_level=3):\n",
    "                lib = relay.build(mod, target=target, params=params)\n",
    "    else:\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "                lib = relay.build(mod, target=target, params=params)\n",
    "        \n",
    "    # Load the compiled module onto the device\n",
    "    dev = tvm.device(str(target), 0)\n",
    "    module = runtime.GraphModule(lib[\"default\"](dev))\n",
    "    return module\n",
    "\n",
    "\n",
    "batch_size=50\n",
    "# Run TVM relay with two different log files\n",
    "logfile_path_conv2d = \"/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tuning-logs/longer-tune/log256/conv2d/vit_conv2d.log\"\n",
    "logfile_path_all = \"/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tuning-logs/longer-tune/log256/all/vit.log\"\n",
    "\n",
    "# Generate modules\n",
    "module_base = tvm_relay_with_file('vit', batch_size, None)\n",
    "module_conv2d = tvm_relay_with_file('vit', batch_size, logfile_path_conv2d)\n",
    "module_all = tvm_relay_with_file('vit', batch_size, logfile_path_all)\n",
    "\n",
    "# Dummy mean times: Replace these with actual measured times\n",
    "mean_pytorch = pytime['mean']\n",
    "mean_time_base= timit(run_module, module_base)['mean']\n",
    "mean_time_conv2d = timit(run_module, module_conv2d)['mean']\n",
    "mean_time_all = timit(run_module, module_all)['mean']\n",
    "\n",
    "# Save the mean times to variables instead of files\n",
    "timing_results_list = [\n",
    "    (batch_size, mean_pytorch),\n",
    "    (batch_size, mean_time_base),\n",
    "    (batch_size, mean_time_conv2d),\n",
    "    (batch_size, mean_time_all)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ecf13-f5dd-4481-9a32-a87db2ca39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_timing_results(timing_results_list, labels, model, dataset):\n",
    "    if not timing_results_list or not labels:\n",
    "        print(\"No timing results or labels provided.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 8))  # Adjust figsize if needed\n",
    "\n",
    "    # Define colors for PyTorch, TVM, Autotune_conv2d, and Autotune_all\n",
    "    color_map = {\n",
    "        'PyTorch': 'orange', \n",
    "        'TVM': 'lightblue', \n",
    "        'Autotune_conv2d': 'darkblue', \n",
    "        'Autotune_all': 'purple'\n",
    "    }\n",
    "    \n",
    "    # Ensure PyTorch is the first label and its timing results are first in the list\n",
    "    if 'PyTorch' not in labels:\n",
    "        print(\"PyTorch timing results not provided.\")\n",
    "        return\n",
    "\n",
    "    if labels[0] != 'PyTorch':\n",
    "        pytorch_index = labels.index('PyTorch')\n",
    "        labels.insert(0, labels.pop(pytorch_index))\n",
    "        timing_results_list.insert(0, timing_results_list.pop(pytorch_index))\n",
    "\n",
    "    # Plot vertical bars for mean timing results\n",
    "    batch_size, _ = timing_results_list[0]  # All results should have the same batch size\n",
    "    x_ticks = np.arange(1)  \n",
    "\n",
    "    # Set bar width and spacing\n",
    "    bar_width = 0.1  # Thinner bars\n",
    "    spacing = 0.2  # Less spacing\n",
    "\n",
    "    for i, ((_, mean), label) in enumerate(zip(timing_results_list, labels)):\n",
    "        if mean is not None:  # Only plot if mean is available\n",
    "            plt.bar(x_ticks + i * (bar_width + spacing), mean, color=color_map.get(label, 'black'), width=bar_width)\n",
    "            plt.text(x_ticks + i * (bar_width + spacing), mean, f'{mean:.3f}s', ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "    # Set x-axis ticks and labels\n",
    "    plt.xticks([0.1], [50], fontsize=12)  # Adjust position to align with thinner bars\n",
    "\n",
    "    plt.title(f'Execution on Nvidia GPU 2080ti\\nModel: {model}, Dataset: {dataset}', fontsize=24)\n",
    "    plt.xlabel('Batch Size', fontsize=24)\n",
    "    plt.ylabel('Mean Execution Time (seconds)', fontsize=24)\n",
    "    \n",
    "    # Define custom legend labels and handles with corresponding colors\n",
    "    custom_handles = [plt.Rectangle((0,0),1,1, color=color_map[label]) for label in labels]\n",
    "    custom_labels = labels  # Use provided labels directly\n",
    "    \n",
    "    # Display legend with custom labels and handles\n",
    "    plt.legend(custom_handles, custom_labels, loc='upper center', fontsize=12)\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "labels = ['PyTorch', 'TVM', 'Autotune_conv2d', 'Autotune_all']\n",
    "plot_timing_results(timing_results_list, labels, model='vit', dataset='ImageNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97862c4-8fd6-474d-933f-f19b82519e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ab8e3-676c-4c98-9200-f10c8a410d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm",
   "language": "python",
   "name": "tvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
