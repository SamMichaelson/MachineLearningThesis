{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3325f29e-48f9-4730-9c0e-d3247fedb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relay, autotvm\n",
    "import tvm.relay.testing\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "from tvm.contrib import graph_executor\n",
    "import tvm.runtime\n",
    "import pickle\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "import onnx\n",
    "from transformers import AutoImageProcessor, FlaxResNetForImageClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc04bcb-733b-4a8c-a3df-1facca8ed202",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([            \n",
    "     transforms.Resize(256),                    \n",
    "     transforms.CenterCrop(224),                \n",
    "     transforms.ToTensor(),                     \n",
    "     transforms.Normalize(                      \n",
    "     mean=[0.485, 0.456, 0.406],                \n",
    "     std=[0.229, 0.224, 0.225]                  \n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9549ba9c-4e25-4a1f-a343-53de1bf57974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_labels(imgs, labels):\n",
    "    if len(imgs.shape) == 3:  # If there's only one image, reshape it to add a batch dimension\n",
    "        imgs = imgs[np.newaxis, :]\n",
    "        labels = [labels]\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))\n",
    "\n",
    "    # If there's only one image, `axes` is not a list. Convert it to a list for consistency.\n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
    "        img = img.squeeze(0)  # Remove the batch dimension if it exists\n",
    "        img = np.transpose(img, (1, 2, 0))  # Change the dimension order from CxHxW to HxWxC\n",
    "        img = img - img.min()\n",
    "        img = img / img.max()\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(label, fontsize=10, pad=5)  # Display label on top of the image\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def load_random_images(batch_size):\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    files = os.listdir(directory)\n",
    "    image_files = [f for f in files if f.endswith('.JPEG')]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory.\")\n",
    "        return None\n",
    "    \n",
    "    imgs = []\n",
    "    chosen_image_files = []\n",
    "    for _ in range(batch_size):\n",
    "        random_image = random.choice(image_files)\n",
    "        img_path = os.path.join(directory, random_image)\n",
    "        chosen_image_files.append(img_path)  # Append the chosen image file path\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    \n",
    "    with open(\"image_files.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(chosen_image_files))\n",
    "    \n",
    "    return imgs\n",
    "\n",
    "def get_images():\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    file_path = \"image_files.txt\"  # Changed to the relative path of image_files.txt\n",
    "    with open(file_path, \"r\") as f:\n",
    "        image_files = f.read().splitlines()\n",
    "    \n",
    "    imgs = []\n",
    "    for image_file in image_files:\n",
    "        img = Image.open(image_file).convert(\"RGB\")  # Load the image using the file path\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef5cb92-9c09-44e7-aaf7-9daf787184a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_class(predictions):\n",
    "    with open('imagenet_classes.txt') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    synsets_to_names = {}\n",
    "    with open('imagenet_synsets.txt') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ', 1)\n",
    "            synsets_to_names[parts[0]] = parts[1]\n",
    "\n",
    "    batch_classes = []\n",
    "    for prediction in predictions:\n",
    "        class_name = synsets_to_names[classes[prediction]]\n",
    "        batch_classes.append(class_name)\n",
    "\n",
    "    return batch_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f71d1f-9f05-40dc-93f6-91468f93224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timit(func, *args, **kwargs):\n",
    "    timing_number = 10\n",
    "    timing_repeat = 10\n",
    "    \n",
    "    warmup_results = timeit.repeat(lambda: func(*args, **kwargs), repeat=timing_repeat, number=timing_number)\n",
    "    timing_results = timeit.repeat(lambda: func(*args, **kwargs), repeat=timing_repeat, number=timing_number)\n",
    "    \n",
    "    timing_summary = {\n",
    "        \"mean\": sum(timing_results) / len(timing_results),\n",
    "        \"median\": sorted(timing_results)[len(timing_results)//2],\n",
    "        \"std\": np.std(timing_results),\n",
    "    }\n",
    "    \n",
    "    print(\"Timing Summary:\")\n",
    "    print(timing_summary)\n",
    "    return timing_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed9b057a-5d4d-4136-8c4c-f8ecea9925c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_exists_in_db(device, network, batch_size, db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = '''\n",
    "    SELECT COUNT(*) FROM device_models\n",
    "    WHERE device = ? AND model = ? AND batch_size = ?\n",
    "    '''\n",
    "    \n",
    "    cursor.execute(query, (device, network, batch_size))\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return result[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a3d942-1a1d-4fc7-869d-9fb8f3bde463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_lib():\n",
    "    filepath = f'/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tvm_report/automated_database/{device}/{network}/{batch_size}'\n",
    "    print(\"Load lib from database...\")\n",
    "    so_files = list(Path(filepath).glob('*.so'))\n",
    "    if not so_files:\n",
    "        raise ValueError(f\"No .so files found in {filepath}\")\n",
    "    path_lib = str(so_files[0])\n",
    "    lib = tvm.runtime.load_module(path_lib)\n",
    "    \n",
    "    return lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a590187-8369-494c-bf33-b022d4f3ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(name, batch_size, input_data):\n",
    "    input_shape = (batch_size, 3, 224, 224)\n",
    "    dtype = \"float32\"\n",
    "\n",
    "    if \"resnet\" in name:\n",
    "        \n",
    "        shape_list = [('data', input_shape)]\n",
    "        torch_model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1').eval()\n",
    "        scripted_model = torch.jit.trace(torch_model, input_data).eval()\n",
    "        mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    elif name == \"vit\":\n",
    "        model_path = \"/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tvm_report/model.onnx\"\n",
    "        onnx_model = onnx.load(model_path)\n",
    "        input_names = [input.name for input in onnx_model.graph.input]\n",
    "        print(\"Input names in ONNX model:\", input_names)\n",
    "\n",
    "        shape_dict = {'pixel_values': input_shape}  # Corrected line\n",
    "        mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "        return mod, params\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported network: \" + name)\n",
    "\n",
    "    return mod, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c596751-2692-47e6-9969-5a3b05158587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_module(mod):\n",
    "    mod.run()\n",
    "    return mod\n",
    "\n",
    "from tvm.ir import IRModule\n",
    "def create_module(tuned_lib, imgs, device, network, target):\n",
    "    dtype = \"float32\"\n",
    "    \n",
    "    if(device==\"cuda\"):\n",
    "        dev = tvm.cuda(0)\n",
    "    elif(device==\"llvm\"):\n",
    "        dev = tvm.cpu()\n",
    "    mod,params = get_model_params( network, batch_size, imgs)\n",
    "    \n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        if isinstance(tuned_lib, (IRModule, _function.Function)):\n",
    "            lib = relay.build_module.build(tuned_lib, target=target, params=params)\n",
    "    \n",
    "    module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "\n",
    "    images = np.array(imgs).astype(dtype)\n",
    "    input_name=\"data\"\n",
    "    if(network == \"vit\"):\n",
    "        input_name = \"pixel_values\"\n",
    "    module.set_input(input_name, tvm.nd.array(images.astype(\"float32\")), **params)\n",
    "    # module.set_input(input_name, tvm.nd.array(images.astype(\"float32\")))\n",
    "    \n",
    "    mod = run_module(module)\n",
    "    output = mod.get_output(0).asnumpy()\n",
    "\n",
    "    print(\"Max values per output:\", np.max(output, axis=1))\n",
    "    prediction = np.argmax(output, axis=1)\n",
    "    print(\"Predictions:\", prediction)\n",
    "\n",
    "    classes = prediction_to_class(prediction)\n",
    "    return classes, module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e18471-35e6-423e-9bd4-b8a5f113246a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load lib from database...\n",
      "Input names in ONNX model: ['pixel_values']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m lib\u001b[38;5;241m=\u001b[39m fetch_lib()\n\u001b[1;32m     18\u001b[0m imgs \u001b[38;5;241m=\u001b[39m load_random_images(batch_size)\n\u001b[0;32m---> 20\u001b[0m classes,module \u001b[38;5;241m=\u001b[39m create_module(lib, imgs, device, network, target)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(lib)\n\u001b[1;32m     23\u001b[0m display_images_with_labels(imgs, classes)\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mcreate_module\u001b[0;34m(tuned_lib, imgs, device, network, target)\u001b[0m\n\u001b[1;32m     13\u001b[0m mod,params \u001b[38;5;241m=\u001b[39m get_model_params( network, batch_size, imgs)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tvm\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mPassContext(opt_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuned_lib, (IRModule, _function\u001b[38;5;241m.\u001b[39mFunction)):\n\u001b[1;32m     17\u001b[0m         lib \u001b[38;5;241m=\u001b[39m relay\u001b[38;5;241m.\u001b[39mbuild_module\u001b[38;5;241m.\u001b[39mbuild(tuned_lib, target\u001b[38;5;241m=\u001b[39mtarget, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m     19\u001b[0m module \u001b[38;5;241m=\u001b[39m graph_executor\u001b[38;5;241m.\u001b[39mGraphModule(lib[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m](dev))\n",
      "\u001b[0;31mNameError\u001b[0m: name '_function' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load random images\n",
    "    batch_size = 2\n",
    "    target = tvm.target.Target(\"cuda\")\n",
    "    device = \"cuda\"\n",
    "    # network = \"resnet-18\"\n",
    "    network = \"vit\"\n",
    "    # network = \"vgg-11\"\n",
    "    # network = \"inception_v3\"\n",
    "    #network = \"squeezenet_v1.1\"\n",
    "    \n",
    "    db_path = '/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tvm_report/automate_tvm.db'\n",
    "    \n",
    "    # Check if model exists in the database\n",
    "    if model_exists_in_db(device, network, batch_size, db_path):\n",
    "        lib= fetch_lib()\n",
    "\n",
    "        imgs = load_random_images(batch_size)\n",
    "        \n",
    "        classes,module = create_module(lib, imgs, device, network, target)\n",
    "        print(lib)\n",
    "\n",
    "        display_images_with_labels(imgs, classes)\n",
    "\n",
    "        timing_summary = timit(run_module, module)\n",
    "    \n",
    "    else:\n",
    "        print(\"Model does not exist in the database or path is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6bf89-7d63-47df-8381-d70e7922d1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804debc-0242-4677-aca1-268a591abdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590b745-b8b3-4767-8046-af0abf1725e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3af3c-5ce2-4c70-b91b-d90c5fac38dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm",
   "language": "python",
   "name": "tvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
