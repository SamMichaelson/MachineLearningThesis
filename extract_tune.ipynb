{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cd161d-3924-4ccc-bd35-2fb929fdc833",
   "metadata": {},
   "source": [
    "## A comparison between Pytorch ,TVM and Auto-TVM for timing in classification of a small model like resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451a4dec-89a9-4cc7-a70d-11db2370a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timeit\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101a110-fcac-4d2f-9f42-325bd1763739",
   "metadata": {},
   "source": [
    "## Fetch the model\n",
    "The model we are using is basic but functional. Also we are not here for training classification models so we will use the pretrained resnet-18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7840780f-72cc-46b7-bfae-db81027e329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) is available.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_model_and_batch_size(batch_size):\n",
    "    batch_size=batch_size\n",
    "    model_name = \"resnet18\"\n",
    "    model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
    "    #model = getattr(models, model_name)(pretrained=True)\n",
    "    model = model.eval()\n",
    "    return model, batch_size\n",
    "\n",
    "def check_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA (GPU) is available.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) is not available. Using CPU instead.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "batch_size = 10\n",
    "device = check_device()\n",
    "model, batch_size = load_model_and_batch_size(batch_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ca37c-ab6b-4b0b-9a20-30fad4db23c9",
   "metadata": {},
   "source": [
    "## Load test images\n",
    "Lets begin by creating some functions that will convert the image to the correct size for resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfbb1a5-c94f-40ec-8758-2f6809f0565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([            \n",
    "     transforms.Resize(256),                    \n",
    "     transforms.CenterCrop(224),                \n",
    "     transforms.ToTensor(),                     \n",
    "     transforms.Normalize(                      \n",
    "     mean=[0.485, 0.456, 0.406],                \n",
    "     std=[0.229, 0.224, 0.225]                  \n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0adb09eb-e6f4-4fca-b457-6ac39093e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_labels(imgs, labels, system):\n",
    "    num_images = len(imgs)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))  # Adjust figsize as needed\n",
    "    \n",
    "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
    "        img = img.squeeze(0)  # Remove the batch dimension if it exists\n",
    "        if(system==\"pytorch\"):\n",
    "            img = img.permute(1, 2, 0)  # Change the image tensor shape from (C, H, W) to (H, W, C)\n",
    "        elif(system==\"tvm\"):\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "        else:\n",
    "            print(\"Wrong System please select tvm or pytorch\")\n",
    "        # Normalize pixel values to [0, 1]\n",
    "        img = img - img.min()\n",
    "        img = img / img.max()\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(label, fontsize=10, pad=5)  # Display label on top of the image\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def load_random_images(batch_size):\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    files = os.listdir(directory)\n",
    "    image_files = [f for f in files if f.endswith('.JPEG')]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory.\")\n",
    "        return None\n",
    "    \n",
    "    imgs = []\n",
    "    chosen_image_files = []\n",
    "    for _ in range(batch_size):\n",
    "        random_image = random.choice(image_files)\n",
    "        img_path = os.path.join(directory, random_image)\n",
    "        chosen_image_files.append(img_path)  # Append the chosen image file path\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    \n",
    "    with open(\"image_files.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(chosen_image_files))\n",
    "    \n",
    "    return imgs\n",
    "\n",
    "def get_images():\n",
    "    directory = \"/home1/public/misampson/dataset/ILSVRC2015/Data/DET/test\"\n",
    "    file_path = \"image_files.txt\"  # Changed to the relative path of image_files.txt\n",
    "    with open(file_path, \"r\") as f:\n",
    "        image_files = f.read().splitlines()\n",
    "    \n",
    "    imgs = []\n",
    "    for image_file in image_files:\n",
    "        img = Image.open(image_file).convert(\"RGB\")  # Load the image using the file path\n",
    "        img_reshape = img.resize((224, 224))\n",
    "        img_t = transform(img_reshape)\n",
    "        imgs.append(img_t)\n",
    "    \n",
    "    imgs = torch.stack(imgs)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef2394-f2ca-4452-bc39-cd025e785bb4",
   "metadata": {},
   "source": [
    "## Prepare the classes\n",
    "Functions that print the results of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9748f428-d9fa-4d6a-b36d-cdcc89e46804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_class(predictions):\n",
    "    with open('imagenet_classes.txt') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    synsets_to_names = {}\n",
    "    with open('imagenet_synsets.txt') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ', 1)\n",
    "            synsets_to_names[parts[0]] = parts[1]\n",
    "\n",
    "    batch_classes = []\n",
    "    for prediction in predictions:\n",
    "        class_name = synsets_to_names[classes[prediction]]\n",
    "        batch_classes.append(class_name)\n",
    "\n",
    "    return batch_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5760e95b-0d57-4920-8111-ed96f1ccb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timit(func, *args, **kwargs):\n",
    "    timing_number = 10\n",
    "    timing_repeat = 10\n",
    "    \n",
    "    warmup_results = timeit.repeat(lambda: func(*args, **kwargs), repeat=timing_repeat, number=timing_number)\n",
    "    timing_results = timeit.repeat(lambda: func(*args, **kwargs), repeat=timing_repeat, number=timing_number)\n",
    "    \n",
    "    timing_summary = {\n",
    "        \"mean\": sum(timing_results) / len(timing_results),\n",
    "        \"median\": sorted(timing_results)[len(timing_results)//2],\n",
    "        \"std\": np.std(timing_results),\n",
    "    }\n",
    "    \n",
    "    print(\"Timing Summary:\")\n",
    "    print(timing_summary)\n",
    "    return timing_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a3bd118-c84e-4594-b30b-6f57fda2a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_pytorch(imgs):\n",
    "#     imgs=imgs.to(device)\n",
    "#     output = model(imgs)\n",
    "#     return output\n",
    "    \n",
    "# def process_pytorch(model, batch_size):\n",
    "#     imgs = get_images()\n",
    "#     print(imgs.shape)\n",
    "#     labels = [] \n",
    "#     out = run_pytorch(imgs)  \n",
    "#     print(out.shape)\n",
    "#     for outputs in out:\n",
    "#         _, indices = torch.topk(outputs, 1)\n",
    "#         img_labels = prediction_to_class(indices) \n",
    "#         labels.append(img_labels)\n",
    "#     return imgs, labels\n",
    "\n",
    "# load_random_images(batch_size)\n",
    "# imgs, labels = process_pytorch(model, batch_size)\n",
    "# #display_images_with_labels(imgs, labels, \"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a7e9e-423b-4a91-b2e1-0172d5d1e518",
   "metadata": {},
   "source": [
    "## TVM without autotuning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defaa58d-4c1e-4cd7-aa20-c0f4e1152c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay, autotvm\n",
    "import tvm.relay.testing\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "from tvm.contrib import graph_executor\n",
    "import tvm.runtime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ef9252-b07c-4c3c-93f9-6205c15ed808",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvm_lib = None\n",
    "tvm_inp_name = None\n",
    "target = tvm.target.Target(\"cuda\")\n",
    "dev = tvm.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adcd4658-2bee-42f6-89fb-db9d421ed506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvm_relay(batchsize):\n",
    "    input_shape = [batchsize,3,224,224]\n",
    "    input_name = \"data\"\n",
    "    shape_list = [(input_name, input_shape)]\n",
    "    input_data = torch.randn(input_shape,device='cuda')\n",
    "    scripted_model = torch.jit.trace(model.to(device), input_data).eval()\n",
    "    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "    return lib,input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81586aad-0497-43fb-9700-741377204a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_module(mod):\n",
    "    mod.run()\n",
    "    return mod\n",
    "\n",
    "def create_module(lib, imgs, input_name, batchsize):\n",
    "    dtype = \"float32\"\n",
    "    module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "    images_cpu = imgs.cpu()\n",
    "    images_np = np.array(images_cpu).reshape((batchsize, 3, 224, 224))\n",
    "    \n",
    "    # Convert NumPy array to TVM tensor\n",
    "    images_tvm = tvm.nd.array(images_np.astype(dtype))\n",
    "    \n",
    "    module.set_input(input_name, images_tvm)\n",
    "    mod = run_module(module)\n",
    "    output = mod.get_output(0).asnumpy()\n",
    "    prediction = np.argmax(output, axis=1)\n",
    "    classes = prediction_to_class(prediction)\n",
    "    return classes, module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15571819-b8b6-482d-b18d-98301338f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tvm(imgs,batchsize):\n",
    "    global tvm_lib, tvm_inp_name\n",
    "    imgs=imgs.to(device)\n",
    "    if tvm_lib is None or tvm_inp_name is None:\n",
    "        print(\"Loading relay for TVM module.\")\n",
    "        lib, inp_name = tvm_relay(batchsize)\n",
    "        tvm_lib = lib  # Store the TVM module globally\n",
    "        tvm_inp_name = inp_name  # Store the input name globally\n",
    "    \n",
    "    classes ,module = create_module(tvm_lib, imgs, tvm_inp_name,batchsize) \n",
    "    return imgs, classes, module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c13a30-0b27-4abc-9a14-becb74fe21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_random_images(batch_size)\n",
    "# model, batch_size = load_model_and_batch_size(batch_size)\n",
    "# imgs,classes, module=run_tvm(get_images(),batch_size)\n",
    "# #display_images_with_labels(imgs, classes, \"tvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d0a2fd-07b7-4655-afe9-c8560725459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvm_wo_autotune_time=timit(run_module,module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8625338-ccbd-4e01-b058-cb45e5ad64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def execute_and_plot_tvm_timit():\n",
    "    global tvm_lib, tvm_inp_name\n",
    "    batch_sizes = [1, 10, 100, 200, 256]\n",
    "    timing_results = []\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        #we want to enter relay for each batch\n",
    "        tvm_lib = None\n",
    "        tvm_inp_name = None\n",
    "        load_random_images(batch_size)\n",
    "        model, batch_size = load_model_and_batch_size(batch_size)\n",
    "        imgs,classes, module=run_tvm(get_images(),batch_size)\n",
    "        tvm_wo_autotune_time=timit(run_module,module)\n",
    "        mean_time = tvm_wo_autotune_time[\"mean\"]\n",
    "        save_mean_time(batch_size, mean_time)\n",
    "\n",
    "    timing_results = get_timing_results(batch_sizes)  # Retrieve timing results from saved files\n",
    "    plot_timing_results(timing_results)\n",
    "\n",
    "\n",
    "def save_mean_time(batch_size, mean_time):\n",
    "    with open(f'tvm_timing_batch_{batch_size}.txt', 'w') as f:\n",
    "        f.write(str(mean_time))\n",
    "\n",
    "def get_timing_results(batch_sizes):\n",
    "    timing_results = []\n",
    "    for batch_size in batch_sizes:\n",
    "        with open(f'tvm_timing_batch_{batch_size}.txt', 'r') as f:\n",
    "            mean_time = float(f.read())\n",
    "        timing_results.append((batch_size, mean_time))\n",
    "    return timing_results\n",
    "\n",
    "def plot_timing_results(timing_results):\n",
    "    # Remove None values from timing_results\n",
    "    timing_results = [result for result in timing_results if result is not None]\n",
    "\n",
    "    if not timing_results:\n",
    "        print(\"No timing results to plot.\")\n",
    "        return\n",
    "\n",
    "    timing_results.sort(key=lambda x: x[1])  # Sort by mean time\n",
    "    batch_sizes = [result[0] for result in timing_results]  # Extract batch sizes\n",
    "    timing_means = [result[1] for result in timing_results]  # Extract timing results\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Generate equally spaced y-axis ticks\n",
    "    y_ticks = np.arange(len(batch_sizes))\n",
    "\n",
    "    # Plot horizontal bars for mean timing results\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(batch_sizes)))  # Generate different colors\n",
    "    for i, (mean, size) in enumerate(zip(timing_means, batch_sizes)):\n",
    "        plt.barh(y_ticks[i], mean, color=colors[i], label=f'Batch Size {size}')\n",
    "\n",
    "    # Set y-axis ticks and labels\n",
    "    plt.yticks(y_ticks, batch_sizes)\n",
    "\n",
    "    plt.title('PyTorch Mean Execution Time vs Batch Size')\n",
    "    plt.xlabel('Mean Execution Time (seconds)')\n",
    "    plt.ylabel('Batch Size')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)  # Remove background grid lines\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the smallest batch size at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "#execute_and_plot_tvm_timit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ba971-ff62-4fcd-83e3-763da64bdf84",
   "metadata": {},
   "source": [
    "## Begin TVM steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "15e98749-f869-42b2-a4c1-b7ed537a1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm.relay.testing\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "import tvm.contrib.graph_executor as runtime\n",
    "import tvm.auto_scheduler as auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3e9eb-f5d5-4993-85b8-8aef35a4339e",
   "metadata": {},
   "source": [
    "## Define Network\n",
    "First we need to define the network in relay frontend API.\n",
    "We can load some pre-defined network from :code:`tvm.relay.testing`.\n",
    "We can also load models from MXNet, ONNX and TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d1dba6e1-970a-4f9e-8570-2c095238a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(name, batch_size):\n",
    "    \"\"\"Get the symbol definition and random weight of a network\"\"\"\n",
    "    input_shape = (batch_size, 3, 224, 224)\n",
    "    output_shape = (batch_size, 1000)\n",
    "\n",
    "    if \"resnet\" in name:\n",
    "        n_layer = int(name.split(\"-\")[1])\n",
    "        mod, params = relay.testing.resnet.get_workload(\n",
    "            num_layers=n_layer, batch_size=batch_size, dtype=dtype\n",
    "        )\n",
    "    elif \"vgg\" in name:\n",
    "        n_layer = int(name.split(\"-\")[1])\n",
    "        mod, params = relay.testing.vgg.get_workload(\n",
    "            num_layers=n_layer, batch_size=batch_size, dtype=dtype\n",
    "        )\n",
    "    elif name == \"mobilenet\":\n",
    "        mod, params = relay.testing.mobilenet.get_workload(batch_size=batch_size, dtype=dtype)\n",
    "    elif name == \"squeezenet_v1.1\":\n",
    "        mod, params = relay.testing.squeezenet.get_workload(\n",
    "            batch_size=batch_size, version=\"1.1\", dtype=dtype\n",
    "        )\n",
    "    elif name == \"inception_v3\":\n",
    "        input_shape = (batch_size, 3, 299, 299)\n",
    "        mod, params = relay.testing.inception_v3.get_workload(batch_size=batch_size, dtype=dtype)\n",
    "    elif name == \"mxnet\":\n",
    "        # an example for mxnet model\n",
    "        from mxnet.gluon.model_zoo.vision import get_model\n",
    "\n",
    "        block = get_model(\"resnet18_v1\", pretrained=True)\n",
    "        mod, params = relay.frontend.from_mxnet(block, shape={\"data\": input_shape}, dtype=dtype)\n",
    "        net = mod[\"main\"]\n",
    "        net = relay.Function(\n",
    "            net.params, relay.nn.softmax(net.body), None, net.type_params, net.attrs\n",
    "        )\n",
    "        mod = tvm.IRModule.from_expr(net)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported network: \" + name)\n",
    "\n",
    "    return mod, params, input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb9a1b-1f78-4956-ae90-e9555e15fd8d",
   "metadata": {},
   "source": [
    "## Set Tuning Options\n",
    "Before tuning, we apply some configurations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d01ea002-ac1a-4021-a9ac-f628350237dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEVICE CONFIG ####\n",
    "target = tvm.target.cuda()\n",
    "\n",
    "#### TUNING OPTION ####\n",
    "network = \"resnet-18\"\n",
    "log_file = \"%s.log\" % network\n",
    "dtype = \"float32\"\n",
    "\n",
    "tuning_option = {\n",
    "    \"log_filename\": log_file,\n",
    "    \"tuner\": \"ga\",\n",
    "    \"n_trial\": 2000,\n",
    "    \"early_stopping\": 20,\n",
    "    \"measure_option\": autotvm.measure_option(\n",
    "        builder=autotvm.LocalBuilder(timeout=10),\n",
    "        runner=autotvm.LocalRunner(number=10, repeat=10, timeout=15, min_repeat_ms=150),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a49ca3-8969-42e3-bf98-23314fadbbbb",
   "metadata": {},
   "source": [
    "## Begin Tuning\n",
    "Now we can extract tuning tasks from the network and begin tuning.\n",
    "Here, we provide a simple utility function to tune a list of tasks.\n",
    "This function is just an initial implementation which tunes them in sequential order.\n",
    "We will introduce a more sophisticated tuning scheduler in the future.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0b96d-f1e3-4328-9efd-3b23ebd6d315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a476ac8f-b221-446d-9cd5-d529590e7eb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab03ab-0355-4daa-83bf-5aae874d89c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37486a-f78c-4b15-845d-4ce068d70f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1a8dd31b-8d2b-4880-928b-a48818290e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tvm\n",
    "from tvm import autotvm\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "\n",
    "def tune_tasks(\n",
    "    tasks,\n",
    "    measure_option,\n",
    "    tuner=\"xgb_rank_itervar\",\n",
    "    n_trial=1000,\n",
    "    early_stopping=20,\n",
    "    log_filename=\"tuning.log\",\n",
    "    use_transfer_learning=False,\n",
    "):\n",
    "    # create tmp log file\n",
    "    tmp_log_file = log_filename + \".tmp\"\n",
    "    if os.path.exists(tmp_log_file):\n",
    "        os.remove(tmp_log_file)\n",
    "\n",
    "    for i, tsk in enumerate(tasks):\n",
    "        prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "        \n",
    "        # Added print statement to indicate the start of tuning for each task\n",
    "        print(f\"\\nStarting tuning for {prefix.strip()}\")\n",
    "\n",
    "        # create tuner\n",
    "        if tuner == \"xgb\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\")\n",
    "        elif tuner == \"xgb_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"reg\", feature_type=\"curve\")\n",
    "        elif tuner == \"xgb_rank\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\")\n",
    "        elif tuner == \"xgb_rank_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_rank_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_rank_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"curve\")\n",
    "        elif tuner == \"xgb_rank_binary\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\")\n",
    "        elif tuner == \"xgb_rank_binary_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"knob\")\n",
    "        elif tuner == \"xgb_rank_binary_itervar\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"itervar\")\n",
    "        elif tuner == \"xgb_rank_binary_curve\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank-binary\", feature_type=\"curve\")\n",
    "        elif tuner == \"ga\":\n",
    "            tuner_obj = GATuner(tsk, pop_size=100)\n",
    "        elif tuner == \"random\":\n",
    "            tuner_obj = RandomTuner(tsk)\n",
    "        elif tuner == \"gridsearch\":\n",
    "            tuner_obj = GridSearchTuner(tsk)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid tuner: \" + tuner)\n",
    "\n",
    "        if use_transfer_learning:\n",
    "            if os.path.isfile(tmp_log_file):\n",
    "                tuner_obj.load_history(autotvm.record.load_from_file(tmp_log_file))\n",
    "\n",
    "        # monitor=autotvm.callback.Monitor()\n",
    "        \n",
    "        def tuning_callback(_, inputs, results, loop_idx=[0]):\n",
    "            loop_idx[0] += 1\n",
    "            for inp, res in zip(inputs, results):\n",
    "                config = inp.config\n",
    "                if res.error_no == 0:\n",
    "                    \n",
    "                    all_cost = res.all_cost\n",
    "                    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(res.timestamp))\n",
    "                    GFLOPS = tsk.flop / 1e9\n",
    "                    error = None\n",
    "                    \n",
    "                    print(f\"{prefix} Trial {loop_idx[0]}/{tsk_trial}...\")\n",
    "                    print(\"    Configuration Options:\")\n",
    "                    for k, v in config._entity_map.items():\n",
    "                        print(f\"        {k}: {v}\")\n",
    "\n",
    "                    lencost=len(res.costs)\n",
    "                    print(f\"       Length is:\",lencost)\n",
    "                    for i in range(lencost):\n",
    "                        time_cost = res.costs[i]\n",
    "                        print(f\"    Time Cost[{i}]: {time_cost:.6f} s\")\n",
    "                    #print(f\"    Task: {tsk.name}\")\n",
    "                    #print(f\"    Input Shape: {tsk.args[0]}\")\n",
    "                    #print(f\"    Filter Shape: {tsk.args[1]}\")\n",
    "                    #print(f\"    Strides: {tsk.args[2]}\")\n",
    "                    #print(f\"    Padding: {tsk.args[3]}\")\n",
    "                    #print(f\"    Dilation: {tsk.args[4]}\")\n",
    "                    #print(f\"    Data Type: {tsk.args[5]}\")\n",
    "                    print(f\"    FLOPs: {tsk.flop}\")\n",
    "                    print(f\"    All Cost: {all_cost:.6f} s\")\n",
    "                    print(f\"    Timestamp: {timestamp} \")\n",
    "                    print(f\"    GFLOPS: {GFLOPS:.2f}\")\n",
    "                  \n",
    "        \n",
    "        # do tuning\n",
    "        tsk_trial = min(n_trial, len(tsk.config_space))\n",
    "        tuner_obj.tune(\n",
    "            n_trial=tsk_trial,\n",
    "            early_stopping=early_stopping,\n",
    "            measure_option=measure_option,\n",
    "            callbacks=[\n",
    "                autotvm.callback.progress_bar(tsk_trial, prefix=prefix),\n",
    "                autotvm.callback.log_to_file(tmp_log_file),\n",
    "                # monitor,\n",
    "                tuning_callback\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # pick best records to a cache file\n",
    "    autotvm.record.pick_best(tmp_log_file, log_filename)\n",
    "    os.remove(tmp_log_file)\n",
    "    \n",
    "    # print(\"Collected Scores (FLOPS) during tuning:\")\n",
    "    # print(monitor.trial_scores())\n",
    "    # print(\"Timestamps of each trial:\")\n",
    "    # print(monitor.trial_timestamps())\n",
    "\n",
    "# Uncomment and run the function as needed\n",
    "# module = tune_and_evaluate(tuning_option, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e38e2181-3ca0-4467-9a76-ef08beb52e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate(tuning_opt, batch_size):\n",
    "    # Extract workloads from relay program\n",
    "    print(\"Extract tasks...\")\n",
    "    mod, params, input_shape, out_shape = get_network(network, batch_size)\n",
    "    tasks = autotvm.task.extract_from_program(\n",
    "        mod[\"main\"], target=target, params=params, ops=(relay.op.get(\"nn.conv2d\"),)\n",
    "    )\n",
    "\n",
    "    # Print only the first task\n",
    "    print(\"\\nExtracted task:\")\n",
    "    task = tasks[0]\n",
    "    print(f\"Task 1/1\")\n",
    "    print(f\"  Name: {task.name}\")\n",
    "    print(f\"  Args: {task.args}\")\n",
    "    print(f\"  Workload: {task.workload}\")\n",
    "    print(f\"  Config Space Size: {len(task.config_space)}\")\n",
    "    print(f\"  Target: {task.target}\")\n",
    "    print(f\"  FLOPs: {task.flop}\")\n",
    "    print(f\"  Function: {task.func}\")\n",
    "    print(f\"  KWArgs: {task.kwargs}\")\n",
    "    \n",
    "    # Print detailed configurations for the first task\n",
    "    print(\"  Sample Configurations:\")\n",
    "    for j, config in enumerate(task.config_space):\n",
    "        if j >= 5:\n",
    "            break\n",
    "        print(f\"    Config {j + 1}: {config}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    config = task.config_space.get(0)\n",
    "\n",
    "    measure_input = autotvm.measure.MeasureInput(target=target, task=task, config=config)\n",
    "    builder = autotvm.measure.LocalBuilder(timeout=10, n_parallel=None)\n",
    "    # builder = autotvm.measure.LocalBuilder(timeout=10, n_parallel=None, build_func=\"ndk\")\n",
    "    # builder = autotvm.measure.LocalBuilder(timeout=10, n_parallel=None, build_func=\"stackvm\")\n",
    "\n",
    "    tmp_b4_del = \"/tmp/tmp_b4_del\"\n",
    "    if os.path.exists(tmp_b4_del):\n",
    "        shutil.rmtree(tmp_b4_del)\n",
    "    shutil.copytree(builder.tmp_dir, tmp_b4_del)\n",
    "    print(f\"Contents copied to {tmp_b4_del}\")\n",
    "    print(f\"tmp_dir after init: {builder.tmp_dir}\")\n",
    "\n",
    "    if not hasattr(builder, 'build_kwargs'):\n",
    "        builder.build_kwargs = {}\n",
    "    \n",
    "    print(\"\\nBuilding measure input...\")\n",
    "    build_results = builder.build([measure_input])\n",
    "\n",
    "    print(f\"tmp_dir after build: {builder.tmp_dir}\")\n",
    "    \n",
    "    print(\"\\nBuild Results:\")\n",
    "    for result in build_results:\n",
    "        print(result) \n",
    "        if hasattr(result, 'costs'):\n",
    "            print(f\"  Costs: {result.costs}\")\n",
    "        else:\n",
    "            print(\"  Costs attribute not found.\")\n",
    "        if hasattr(result, 'error_no'):\n",
    "            print(f\"  Error No: {result.error_no}\")\n",
    "        else:\n",
    "            print(\"  Error No attribute not found.\")\n",
    "        if hasattr(result, 'all_cost'):\n",
    "            print(f\"  All Cost: {result.all_cost}\")\n",
    "        else:\n",
    "            print(\"  All Cost attribute not found.\")\n",
    "        if hasattr(result, 'timestamp'):\n",
    "            print(f\"  Timestamp: {result.timestamp}\")\n",
    "        else:\n",
    "            print(\"  Timestamp attribute not found.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Tuning the first task\n",
    "    print(\"Tuning...\")\n",
    "    # tune_tasks([task], **tuning_opt)\n",
    "\n",
    "    # Compile kernels with history best records\n",
    "    with autotvm.apply_history_best(tuning_opt['log_filename']):\n",
    "        print(\"Compile...\")\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = relay.build_module.build(mod, target=target, params=params)\n",
    "\n",
    "        # Load parameters\n",
    "        dev = tvm.device(str(target), 0)\n",
    "        module = runtime.GraphModule(lib[\"default\"](dev))\n",
    "        data_tvm = tvm.nd.array((np.random.uniform(size=input_shape)).astype(dtype))\n",
    "        module.set_input(\"data\", data_tvm)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"Evaluate inference time cost...\")\n",
    "        print(module.benchmark(dev, number=1, repeat=600))\n",
    "        \n",
    "    return module\n",
    "\n",
    "# Uncomment and run the function as needed:\n",
    "# module = tune_and_evaluate(tuning_option, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d9d8ffe-579f-481f-a023-57598958f5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract tasks...\n",
      "\n",
      "Extracted task:\n",
      "Task 1/1\n",
      "  Name: conv2d_nchw.cuda\n",
      "  Args: (('TENSOR', (10, 3, 224, 224), 'float32'), ('TENSOR', (64, 3, 7, 7), 'float32'), (2, 2), (3, 3, 3, 3), (1, 1), 'float32')\n",
      "  Workload: ('conv2d_nchw.cuda', ('TENSOR', (10, 3, 224, 224), 'float32'), ('TENSOR', (64, 3, 7, 7), 'float32'), (2, 2), (3, 3, 3, 3), (1, 1), 'float32')\n",
      "  Config Space Size: 79027200\n",
      "  Target: cuda -keys=cuda,gpu -arch=sm_75 -max_num_threads=1024 -model=unknown -thread_warp_size=32\n",
      "  FLOPs: 2360279040.0\n",
      "  Function: <tvm.autotvm.task.task.TaskTemplate object at 0x7fdca75f7ad0>\n",
      "  KWArgs: {}\n",
      "  Sample Configurations:\n",
      "    Config 1: tile_f\n",
      "    Config 2: tile_y\n",
      "    Config 3: tile_x\n",
      "    Config 4: tile_rc\n",
      "    Config 5: tile_ry\n",
      "\n",
      "Contents copied to /tmp/tmp_b4_del\n",
      "tmp_dir after init: /tmp/tmpgavdd29_\n",
      "\n",
      "Building measure input...\n",
      "tmp_dir after build: /tmp/tmpgtmp9x8i\n",
      "\n",
      "Build Results:\n",
      "BuildResult(filename='/tmp/tmpgtmp9x8i/tmp_func_87e227011be18206.tar', arg_info=(((10, 64, 112, 112), 'float32'), ((64, 3, 7, 7), 'float32'), ((10, 3, 224, 224), 'float32')), error=None, time_cost=1.1102588176727295)\n",
      "  Costs attribute not found.\n",
      "  Error No attribute not found.\n",
      "  All Cost attribute not found.\n",
      "  Timestamp attribute not found.\n",
      "Tuning...\n",
      "Compile...\n",
      "Evaluate inference time cost...\n",
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "   9.5940       9.5230      14.3223       9.3749       0.5696                  \n"
     ]
    }
   ],
   "source": [
    "##### # Uncomment and run the function as needed:\n",
    "module = tune_and_evaluate(tuning_option, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d05d796-1847-4853-95d6-90d9341d98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvm_relay_with_file(network, batch_size):\n",
    "    tuning_logs_dir = \"/home1/public/misampson/resnet-50/git/ITE-Forth-CARV/tuning-logs\"\n",
    "    log_dir = f\"log{batch_size}\"\n",
    "    logfile_path = os.path.join(tuning_logs_dir, \"longer-tune\", log_dir, \"resnet-18.log\")\n",
    "    \n",
    "    mod, params, input_shape, out_shape = get_network(network, batch_size)\n",
    "    \n",
    "    with autotvm.apply_history_best(logfile_path):\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = relay.build(mod, target=target, params=params)\n",
    "    \n",
    "    # Load the compiled module onto the device\n",
    "    dev = tvm.device(str(target), 0)\n",
    "    module = runtime.GraphModule(lib[\"default\"](dev))\n",
    "    return module\n",
    "\n",
    "# module = tvm_relay_with_file(network, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a22145-db20-4f2b-8a00-3760389ff38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing Summary:\n",
      "{'mean': 0.008999020233750344, 'median': 0.009150846395641565, 'std': 0.0001976378763779741}\n",
      "Timing Summary:\n",
      "{'mean': 0.046142653003335, 'median': 0.04624128295108676, 'std': 0.0002371395110089922}\n",
      "Timing Summary:\n",
      "{'mean': 0.3330501952208579, 'median': 0.33302059676498175, 'std': 0.0002002208966988406}\n",
      "Timing Summary:\n",
      "{'mean': 1.0582680746447295, 'median': 1.0577474259771407, 'std': 0.0022788268541794154}\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def execute_and_plot_autotune_timit():\n",
    "    global tvm_lib, tvm_inp_name\n",
    "    batch_sizes = [1, 10, 100, 200, 256]\n",
    "    timing_results = []\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        module = tvm_relay_with_file(network, batch_size)\n",
    "        tvm_wo_autotune_time=timit(run_module,module)\n",
    "        mean_time = tvm_wo_autotune_time[\"mean\"]\n",
    "        save_mean_time(batch_size, mean_time)\n",
    "\n",
    "    timing_results = get_timing_results(batch_sizes)  # Retrieve timing results from saved files\n",
    "    plot_timing_results(timing_results)\n",
    "\n",
    "\n",
    "def save_mean_time(batch_size, mean_time):\n",
    "    with open(f'autotune_timing_batch_{batch_size}.txt', 'w') as f:\n",
    "        f.write(str(mean_time))\n",
    "\n",
    "def get_timing_results(batch_sizes):\n",
    "    timing_results = []\n",
    "    for batch_size in batch_sizes:\n",
    "        with open(f'autotune_timing_batch_{batch_size}.txt', 'r') as f:\n",
    "            mean_time = float(f.read())\n",
    "        timing_results.append((batch_size, mean_time))\n",
    "    return timing_results\n",
    "\n",
    "def plot_timing_results(timing_results):\n",
    "    # Remove None values from timing_results\n",
    "    timing_results = [result for result in timing_results if result is not None]\n",
    "\n",
    "    if not timing_results:\n",
    "        print(\"No timing results to plot.\")\n",
    "        return\n",
    "\n",
    "    timing_results.sort(key=lambda x: x[1])  # Sort by mean time\n",
    "    batch_sizes = [result[0] for result in timing_results]  # Extract batch sizes\n",
    "    timing_means = [result[1] for result in timing_results]  # Extract timing results\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Generate equally spaced y-axis ticks\n",
    "    y_ticks = np.arange(len(batch_sizes))\n",
    "\n",
    "    # Plot horizontal bars for mean timing results\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(batch_sizes)))  # Generate different colors\n",
    "    for i, (mean, size) in enumerate(zip(timing_means, batch_sizes)):\n",
    "        plt.barh(y_ticks[i], mean, color=colors[i], label=f'Batch Size {size}')\n",
    "\n",
    "    # Set y-axis ticks and labels\n",
    "    plt.yticks(y_ticks, batch_sizes)\n",
    "\n",
    "    plt.title('PyTorch Mean Execution Time vs Batch Size')\n",
    "    plt.xlabel('Mean Execution Time (seconds)')\n",
    "    plt.ylabel('Batch Size')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)  # Remove background grid lines\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the smallest batch size at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "execute_and_plot_autotune_timit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc45d64-5d0c-4eb6-8fe9-572df635d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvm_autotune_time=timit(run_module,module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99debf49-5ece-4d5d-aa5b-1133874ed815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timestamps(time1, time2, time3):\n",
    "    # Parse the timestamps to extract mean, median, and standard deviation values\n",
    "    def parse_timestamp(timestamp):\n",
    "        if timestamp is None:\n",
    "            return None, None, None\n",
    "        return timestamp[\"mean\"], timestamp[\"median\"], timestamp[\"std\"]\n",
    "\n",
    "    t1_mean, t1_median, t1_std = parse_timestamp(time1)\n",
    "    t2_mean, t2_median, t2_std = parse_timestamp(time2)\n",
    "    t3_mean, t3_median, t3_std = parse_timestamp(time3)\n",
    "\n",
    "    # Plotting\n",
    "    labels = ['Mean', 'Median', 'Std']\n",
    "    t1_values = [t1_mean, t1_median, t1_std]\n",
    "    t2_values = [t2_mean, t2_median, t2_std]\n",
    "    t3_values = [t3_mean, t3_median, t3_std]\n",
    "\n",
    "    x = range(len(labels))\n",
    "    width = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bars = []\n",
    "    \n",
    "    if t1_mean is not None:\n",
    "        bars.append(ax.bar(x, t1_values, width, label='Pytorch'))\n",
    "    if t2_mean is not None:\n",
    "        bars.append(ax.bar([i + width for i in x], t2_values, width, label='TVM without tuning'))\n",
    "    if t3_mean is not None:\n",
    "        bars.append(ax.bar([i + width*2 for i in x], t3_values, width, label='TVM autotune'))\n",
    "\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Time')\n",
    "    ax.set_title('Classification Timing Comparison')\n",
    "    ax.set_xticks([i + width for i in x])\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    # Add legend only if there are bars plotted\n",
    "    if bars:\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fb8e9-fa39-4c5f-adb9-da43839f2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_timestamps(pytorch_time, tvm_wo_autotune_time, tvm_autotune_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b017-84ab-4aae-92a6-34e05091a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_timestamps(time1, time2, time3):\n",
    "    # Parse the timestamps to extract mean values\n",
    "    def parse_timestamp(timestamp):\n",
    "        if timestamp is None:\n",
    "            return None\n",
    "        return timestamp[\"mean\"]\n",
    "\n",
    "    t1_mean = parse_timestamp(time1)\n",
    "    t2_mean = parse_timestamp(time2)\n",
    "    t3_mean = parse_timestamp(time3)\n",
    "\n",
    "    # Plotting\n",
    "    labels = ['Pytorch', 'TVM without tuning', 'TVM autotune']\n",
    "    means = [t1_mean, t2_mean, t3_mean]\n",
    "\n",
    "    x = range(len(labels))\n",
    "    width = 0.5\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bars = []\n",
    "\n",
    "    if t1_mean is not None:\n",
    "        bars.append(ax.bar(x[0], t1_mean, width, label='Pytorch'))\n",
    "    if t2_mean is not None:\n",
    "        bars.append(ax.bar(x[1], t2_mean, width, label='TVM without tuning'))\n",
    "    if t3_mean is not None:\n",
    "        bars.append(ax.bar(x[2], t3_mean, width, label='TVM autotune'))\n",
    "\n",
    "    ax.set_xlabel('Frameworks')\n",
    "    ax.set_ylabel('Mean Time')\n",
    "    ax.set_title('Mean Classification Time Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    # Add the mean value on top of each bar\n",
    "    for bar in bars:\n",
    "        for b in bar:\n",
    "            height = b.get_height()\n",
    "            ax.annotate(f'{height:.4f}',\n",
    "                        xy=(b.get_x() + b.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2896b-3813-4497-8dca-dd96a0a257dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_timestamps(pytorch_time, tvm_wo_autotune_time, tvm_autotune_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4478cf3-716d-4b73-956b-30f3650b4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_timing_results(file_prefixes, batch_sizes):\n",
    "    timing_results_list = []\n",
    "    for file_prefix in file_prefixes:\n",
    "        timing_results = []\n",
    "        for batch_size in batch_sizes:\n",
    "            file_path = f'{file_prefix}{batch_size}.txt'\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    mean_time = float(f.read())\n",
    "                timing_results.append((batch_size, mean_time))\n",
    "            except FileNotFoundError:\n",
    "                pass  # Skip if file not found for the current batch size\n",
    "        timing_results_list.append(timing_results)\n",
    "    return timing_results_list\n",
    "\n",
    "def plot_timing_results(timing_results_list, labels, model, dataset):\n",
    "    if not timing_results_list or not labels:\n",
    "        print(\"No timing results or labels provided.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))  # Adjust figsize if needed\n",
    "\n",
    "    # Generate equally spaced x-axis ticks\n",
    "    x_ticks = np.arange(len(timing_results_list[0]))\n",
    "    \n",
    "    # Define colors for PyTorch, TVM, and autotune\n",
    "    color_map = {'PyTorch': 'orange', 'TVM': 'lightblue', 'Autotune': 'darkblue'}\n",
    "    \n",
    "    # Plot vertical bars for mean timing results\n",
    "    for i, (timing_results, label) in enumerate(zip(timing_results_list, labels)):\n",
    "        timing_means = [result[1] for result in timing_results]\n",
    "        batch_sizes = [result[0] for result in timing_results]\n",
    "        \n",
    "        for j, (mean, size) in enumerate(zip(timing_means, batch_sizes)):\n",
    "            plt.bar(x_ticks[j] + i * 0.2, mean, color=color_map.get(label, 'black'), width=0.2)\n",
    "            #plt.text(x_ticks[j] + i * 0.2, mean, f'{mean:.3f}s', ha='center', va='bottom', color='black', fontsize=8)\n",
    "\n",
    "    # Set x-axis ticks and labels\n",
    "    if 256 in batch_sizes:\n",
    "        batch_sizes = [size for size in batch_sizes if size != 256] + [256]  # Move batch size 256 to the end\n",
    "    plt.xticks(x_ticks + 0.2 * len(timing_results_list) / 2, batch_sizes, fontsize=12)\n",
    "\n",
    "    plt.title('Execution on Nvidia GPU 2080ti', fontsize=36)\n",
    "    plt.xlabel('Batch Size', fontsize=24)\n",
    "    plt.ylabel('Mean Execution Time (seconds)', fontsize=24)\n",
    "    \n",
    "    # Define custom legend labels and handles with corresponding colors\n",
    "    custom_handles = [plt.Rectangle((0,0),1,1, color=color_map[label]) for label in labels]\n",
    "    custom_labels = labels\n",
    "    \n",
    "    # Display legend with custom labels and handles\n",
    "    plt.legend(custom_handles, custom_labels, loc='upper left', fontsize=12)\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "file_prefixes = ['pytorch_timing_batch_', 'tvm_timing_batch_', 'autotune_timing_batch_']\n",
    "labels = ['PyTorch', 'TVM', 'Autotune']\n",
    "batch_sizes = [1, 10, 100, 200, 256] \n",
    "timing_results_list = get_timing_results(file_prefixes, batch_sizes)\n",
    "plot_timing_results(timing_results_list, labels, model='ResNet-18', dataset='ImageNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8778aa7a-3b8a-4961-8aaf-39309d3da397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdeftmp'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"abc\", \"def\", \"tmp\"]\n",
    "\"\".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ecf13-f5dd-4481-9a32-a87db2ca39ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvm",
   "language": "python",
   "name": "tvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
